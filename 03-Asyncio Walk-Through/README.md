<!-- <div dir='rtl'> -->
<div dir=&quotrtl&quot>

## فصل سوم

## گشت و گذار در Asyncio

> کتاب‌خانه‌ی Asyncio ابزاری دیگر برای برنامه‌نویسی هم‌زمان در پایتون است، که از thread ها یا پردازش چندگانه سبک‌تر است. به زبان ساده، کار خود را با ایجاد یک حلقه event برای اجرای یک مجموعه از کارها انجام می‌دهد؛ با تفاوتی کلیدی که واگذاری مجدد کنترل به حلقه، به خود کار بستگی دارد.
> فیلیپ جونز، [شناخت Asyncio](https://medium.com/@pgjones/understanding-asyncio-a6592a517def)

ای‌پی‌آی asyncio پایتون پیچیده است، چرا که هدف آن حل مسائل گوناگون اقشار مختلف است. متاسفانه، تعداد راهنماهایی که به شما کمک می‌کنند دریابید که کدام بخش‌های asyncio برای تیم شما مهم است، بسیار کم است.

هدف من کمک به شما در حل موضوع بالاست. مخاطب هدف ویژگی‌های async در پایتون دو دسته‌اند:

توسعه‌دهندگان End-user:
این دسته از توسعه‌دهندگان می‌خواهند با asyncio برنامه (اپلیکیشن) بسازند. فرض می‌شود که شما در این دسته هستید.

توسعه‌دهندگان فریم‌ورک:
این دسته از توسعه‌دهندگان، فریم‌ورک‌ها و کتاب‌خانه‌هایی را می‌سازند که توسعه‌دهندگان End-user از آن‌ها در برنامه‌های خود استفاده می‌کنند.

بسیاری از سردرگمی‌ها در باره asyncio به دلیل تفاوت قائل نشدن میان دو دسته بالا از توسعه‌دهندگان است. برای مثال، مستندات رسمی پایتون برای asyncio بیشتر برای توسعه‌دهندگان فریم‌ورک است تا end-user. این یعنی که توسعه‌دهندگان end-user بعد از صرف زمان کمی برای مطالعه آن، به دلیل پیچیدگی ظاهری آن، درب و داغان می‌شوند و مانند لقمه‌ای است که پیش از جویدن باید آن را قورت دهند!

امیدوارم این کتاب به شما کمک کند که میان آن دسته از ویژگی‌های asyncio که برای هر دسته از توسعه‌دهندگان در اولویت است، تمایز قائل شوید.

اگر به جزئیات سطح پایین‌تر در مورد ساختار درونی فریم‌ورک‌های هم‌زمان مانند asyncio علاقه‌مندید، [این سخن‌رانی بی‌نظیر از دیو بیزلی](https://youtu.be/MCs5OvhV9S4) را پیش‌نهاد می‌کنم. او در این سخن‌رانی نشان می‌دهد که چگونه می‌توان نسخه‌ای ساده‌تر از فریم‌ورک ناهم‌زمانی مانند Asyncio را استفاده کرد.

هدف من ایجاد درک پایه‌ای از بنیان‌های asyncio در شماست - در اندازه‌ای که بتوانید برنامه‌های ساده‌ای با آن بنویسید و به مراجع پیچیده‌تر مراجعه کنید.

ابتدا، با ساده‌ترین چیزها شروع می‌کنیم و طی آن، مهم‌ترین اجزای ساخت برنامه‌های ساخته‌شده با asyncio را معرفی می‌کنیم.

### آغاز سریع

شما تنها به دانستن هفت تابع نیاز دارید تا به صورت معمول از asyncio استفاده کنید.

> -یوری سلیوانوف، نویسنده‌ی PEP 492، که طی آن کلیدواژه‌های async و await به پایتون افزوده شد.

عمیق‌شدن در [مستندات رسمی پایتون](https://docs.python.org/3/library/asyncio.html) به نظر ترسناک می‌آید. بخش‌های مختلف آن بسیاری مفاهیم و واژه‌های جدید دارد که حتی برای برنامه‌نویسان باتجربه‌ی پایتون نیز ناآشناست، چرا که Asyncio موضوع جدیدی در پایتون است. من قصد دارم تمام این سختی‌ها را به گام‌های کوچک تبدیل کرده و بعدتر در مورد چگونگی مطالعه این بخش از مستندات پایتون توضیح دهم، اما فعلا تنها نیاز دارید بدانید که آن بخش از این کتاب‌خانه که با آن ممکن است کار کنید، بسیار کم‌حجم‌تر از حد انتظار است.
یوری سلیوانوف، نویسنده‌ی [PEP 492](https://peps.python.org/pep-0492/) و از توسعه‌دهندگان اصلی در تمام مراحل توسعه‌ی async Python، در سخن‌رانی سال 2016 خود در پای‌کان، [async/await در پایتون 3.5 و چرایی فوق‌العاده بودنش](https://youtu.be/m28fiN9y_r8) توضیح می‌دهد که بسیاری از API ها در این ماژول برای طراحان فریم‌ورک نوشته شده و نه توسعه‌دهندگان end-user. او در این سخن‌رانی بر مواردی که توسعه‌دهندگان end-user باید به آن‌ها توجه کنند، تاکید می‌کند. این موارد بخش کوچکی از کل این ماژول هستند و در موارد زیر خلاصه می‌شوند:

<p align="right">
<div>
- شروع event loop مربوط به asyncio
</div>
<div>
- فراخوانی توابع async/await
</div>
<div>
- ایجاد یک کار برای اجرا در این حلقه
</div>
<div>
- انتظار برای اتمام چندین کار
</div>
<div>
- بستن حلقه پس از اتمام کارهای هم‌زمان
</div>
</p>

در این بخش، قصد داریم به این ویژگی‌های اساسی نگاهی بیندازیم و ببینیم چگونه می‌توانیم برنامه‌نویسی رویدادمحور را در پایتون درک کنیم و انجام دهیم.

برنامه Hello World در این ماژول در قالب مثال 3-1 آمده است:

مثال 3-1. برنامه Hello World با Asyncio

```python
# quickstart.py
import asyncio, time
async def main():
    print(f'{time.ctime()} Hello!')
    await asyncio.sleep(1.0)
    print(f'{time.ctime()} Goodbye!')
asyncio.run(main()) #1
```

<p align="right">
1. [ماژول] asyncio تابعی به نام run() دارد که توابع async و دیگر coroutine هایی را که از آن‌جا فراخوانی شده‌اند، مانند sleep()، در تابع main() اجرا می‌کند.
</p>

در زیر، خروجی مثال 3-1 آمده‌است:
          
```shell
$ python quickstart.py
Sun Aug 18 02:14:34 2019 Hello!
Sun Aug 18 02:14:35 2019 Goodbye!
```

در عمل، بیشتر کدهای asyncio-محور شما از تابع run() که در این‌جا نشان داده شده، استفاده می‌کند، اما مهم است که اندکی بیشتر در مورد کاری که این تابع برای شما انجام می‌دهد بدانیم. این دانش از آن جا اهمیت دارد که در طراحی‌های کلان نرم‌افزاری شما تاثیر می‌گذارد.

مثال 3-2 کدی است که من آن را «شبه hello world» می‌نامم. دقیقا کار run() را انجام نمی‌دهد، اما به قدر کافی ایده‌هایی که طی این کتاب به آن‌ها خواهیم پرداخت را معرفی می‌کند. [برای فهم آن] نیاز به دانشی پایه‌ای از coroutine ها (که عمیقا در بخش‌های بعدی این فصل به آن می‌پردازیم) دارید، اما به هر جهت تلاش کنید با آن پیش رفته و فعلا بر مفاهیم سطح بالا تمرکز کنید.

مثال 3-2. شبه hello world با asyncio

```python
# quickstart.py
import asyncio
import time
async def main():
    print(f"{time.ctime()} Hello!")
    await asyncio.sleep(1.0)
    print(f"{time.ctime()} Goodbye!")
loop = asyncio.get_event_loop() #1
task = loop.create_task(main()) #2
loop.run_until_complete(task) #3
pending = asyncio.all_tasks(loop=loop)
for task in pending:
    task.cancel()
group = asyncio.gather(*pending, return_exceptions=True) #4
loop.run_until_complete(group) #3
loop.close() #5
```

<p align="right">
<div>
1. `loop = asyncio.get_event_loop()`
</div>
<div>
- شما نیاز دارید که یک event loop پیش از اجرای هر coroutine ایجاد کنید. این متد در واقع، تا زمانی که از یک thread استفاده کنید، هر بار همان حلقه‌ی وابسته به آن را   برمی‌گرداند. اگر داخل یک تابع async def باشید، باید تابع `asyncio.get_running_loop` را فراخوانی کنید، که نتیجه مورد انتظارتان را برمی‌گرداند. این موضوع با جزئیات بسیار بیشتر در بخش‌های بعدی کتاب پوشش داده می‌شود.
</div>
<div>
2. `task = loop.create_task(coro)`
<div>
- در این حالت، باید به طور خاص `loop.create_task(main())` را فراخوانی کنید. تابع coroutine شما تا زمانی که این کار را انجام ندهید، اجرا نمی‌شود. با این کار، تابع coroutine شما با حلقه اجرا می‌شود. شئ از نوع task ای که برگردانده می‌شود، می‌تواند در ره‌گیری وضعیت تسک استفاده شود (مثلا این که تسک هنوز در حال اجراست یا خاتمه پیدا کرده‌است) یا نتیجه اجرای coroutine تمام‌شده را بدهد. می‌توانید تسک را با متد `task.cancel()` متوقف کنید.
</div>
<div>
3. `loop.run_until_complete(coro)`
</div>
<div>
- فراخوانی این تابع، thread در حال اجرا را - که معمولا thread  اصلی است - متوقف می‌کند. توجه داشته باشید که `run_until_complete()` تنها تا زمانی حلقه را در حال اجرا نگه می‌دارد که  coroutine داده شده کامل شود، اما دیگر تسک‌هایی که برای اجرا در حلقه تنظیم شده‌اند، تا زمانی که حلقه در حال اجراست، اجرا می‌شوند. در پشت صحنه، `asyncio.run()` تابع `run_until_complete()` را فراخوانی کرده و به این ترتیب thread اصلی را به شکلی که توضیح داده شد متوقف می‌کند.
</div>
<div>
4. `group = asyncio.gather(task1, task2, task3)`
</div>
<div>
- زمانی که قسمت main برنامه از توقف، چه به دلیل سیگنالی از سوی پردازش یا توقف حلقه به دلیل فراخوانی loop.stop() از سوی قطعه کدی دیگر، بیرون می‌آید، کدِ پس از `run_until_complete()` اجرا می‌شود. استاندارد معمول، مطابق آن چه در کد بالا آمده، این است که تسک‌های در صف انتظار را مجتمع کنیم، متوقف کنیم و سپس با استفاده مجدد از `loop.run_until_complete()` آن‌ها را انجام دهیم. متد gather() کار جمع‌آوری را انجام می‌دهد. توجه داشته باشید که asyncio.run() تمام کار متوقف‌کردن، جمع‌آوری و انتظار برای تسک‌های در صف تا خاتمه‌ی آن‌ها را انجام می‌دهد.
</div>
<div>
5. `loop.close()`
</div>
<div>
- این متد معمولا حرکت نهایی است: باید بر روی یک حلقه‌ی متوقف‌شده فراخوانی شود. طی آن، تمام صف‌ها پاک شده و اجراکننده خاموش می‌شود. حلقه‌ی متوقف‌شده را می‌توان از نو به کار گرفت، اما حلقه‌ی بسته‌شده برای همیشه از بین می‌رود. پشت صحنه، asyncio.run() حلقه را پیش از بازگرداندن [مقدار مد نظر] می‌بندد. این موضوع مسئله‌ای ندارد، چرا که run() حلقه‌ی event جدیدی را با هربار فراخوانی ایجاد می‌کند.
</div>
</p>
مثال 3-1 نشان می‌دهد که اگر از asyncio.run() استفاده کنید، هیچ کدام از مراحل گفته‌شده را لازم نیست طی کنید. با این حال، مهم است که این مراحل را بفهمیم، چرا که شرایط در عمل پیچیده‌تر می‌شود و شما برای درگیری با چالش‌ها به دانش بیشتری نیاز دارید. بسیاری از این مراحل در قسمت‌های بعدی کتاب ، با جزئیات پوشش داده شده‌اند.
مثال قبل ساده‌تر از آن است که بتواند در عمل به کار بیاید. اطلاعات بیشتری برای ازکارانداختن اصولی [حلقه‌ها] نیاز است. هدف این مثال تنها این بود که مهم‌ترین توابع و متدها را در asyncio معرفی کند. اطلاعات بیشتر و کاربردی در فصل «بالاآوردن و از کارانداختن اصولی» در صفحه 57 آمده است.
این کتاب، مطالب بسیاری را در مورد پشت صحنه‌ی event loopها بیان می‌کند، و از شما می‌خواهد که از مواردی مانند مدیریت چرخه کار آگاهی داشته باشید. این مورد در Node.js متفاوت است - که مثلا، مانند asyncio یک event loop اجرا می‌کند اما تا حدودی آن را از دید توسعه‌دهنده پنهان می‌کند. با این حال، پس از این که قدری با asyncio کار کنید، متوجه می‌وید که الگوی بالاآوردن و ازکارانداختن event loopها، چندان هم از چیزی که در مثال‌ها مطرح شده دور نیست. تعدادی از ریزه‌کاری‌های مدیریت چرخه کار حلقه‌ها را با جزئیات بیشتر، بعدا بررسی خواهیم‌کرد.
من چیزی را از مثال قبل جا گذاشتم. آخرین چیزی که در مورد عمل‌کرد پایه باید بدانید، اجرای توابع متوقف‌کننده است. موضوع در باب چندکارگی همکارانه (cooperative multitasking) این است که نیاز داریم تمام توابع وابسته به ورودی/خروجی خب...با هم هم‌کاری کنند! این بدان معناست که اجازه دهیم چارچوب پشت صحنه، کنترلش با کلیدواژه await به حلقه منتقل شود. بیشتر کدهای پایتون در این روزها این کار را نمی‌کنند و به جای آن، تکیه بر این می‌کنند که چنین توابعی را در thread ها اجرا کنید. تا زمانی که پشتیبانی گسترده‌تری از توابع async نشود، درک خواهید کرد که استفاده از کتاب‌خانه‌ها برای توقف  توابع غیر قابل اجتناب است.

برای این کار، ماژول asyncio یک API بسیار شبیه به APIای که در بسته‌ی `concurrent.features` است، ارائه می‌کند. این بسته یک ThreadPoolExecutor و یک ProcessPoolExecutor در خود دارد. پیش‌فرض آن thread-محور است، اما هر کدام از اجراکننده‌های thread-محور یا پردازش محور می‌تواند استفاده شود. من از مسائل مربوط به اجراکننده در مثال قبل صرف نظر کردم، چرا که توصیف چگونگی جورشدن اجزای بنیادی با یک‌دیگر را پیچیده می‌کند. حال که تمام آن موضوعات پوشش داده شده، می‌توانیم مستقیما با این موضوع روبرو شویم.

تعدادی فوت کوزه‌گری وجود دارد که باید به آن‌ها توجه نمود. با هم قطعه کدی که در مثال 3-3 آمده را ببینیم:

مثال 3-3: واسط پایه‌ای اجراکننده

```python
# quickstart_exe.py
import time
import asyncio
async def main():
    print(f'{time.ctime()} Hello!')
    await asyncio.sleep(1.0)
    print(f'{time.ctime()} Goodbye!')
def blocking(): #1
    time.sleep(0.5) #2
    print(f"{time.ctime()} Hello from a thread!")
loop = asyncio.get_event_loop()
task = loop.create_task(main())
loop.run_in_executor(None, blocking) #3
loop.run_until_complete(task)
pending = asyncio.all_tasks(loop=loop) #4
for task in pending:
    task.cancel()
group = asyncio.gather(*pending, return_exceptions=True)
loop.run_until_complete(group)
loop.close()
```

<ol dir="rtl">
<li>
متد `blocking()` تابع سنتی time.sleep() درون خود فراخوانی می‌کند، که thread اصلی را متوقف کرده و event loop شما را از اجرا باز می‌دارد. این بدان معناست که شما نباید این تابع را  در جایگاه یک coroutine قرار دهید - در واقع، شما در هیچ‌کجای thread اصلی، که حلقه‌ی مربوط به asyncio در حال اجراست، نمی‌توانید این تابع را فراخوانی کنید. این مسئله به وسیله‌ی اجرای این تابع در یک اجراکنند حل می‌شود.
</li>
<li>
موضوعی که در این مورد بیان می‌شود، مربوط به این بخش نیست، اما برای بخش‌های بعد به کار می‌آید: توجه کنید که در main() زمان sleep در حالت توقف (نیم ثانیه) بیشتر از زمان sleep در حالت بدون توقف است (یک ثانیه). این کار، کد را مرتب و تمیز نگه می‌دارد. در «انتظار برای اجراکننده در حین خاموش شدن»، صفحه 68، به این خواهیم پرداخت که در صورت طولانی‌تر شدن زمان اجرای توابع اجراکننده از همتایان async شان در طی از کار افتادن، چه اتفاقی می‌افتد.
</li>
<li>
جزء `await loop.run_in_executor(None, func)` آخرین مورد در لیست موارد پراهمیت ما است. گاهی اوقات نیاز است که کدها را در چارچوب یک thread یا حتی یک پردازش جداگانه اجرا کرد: این متد دقیقا برای همین کار است. در این‌جا تابع متوقف‌کننده را ورودی می‌دهیم تا در اجراکننده‌ی اصلی اجرا شود. توجه کنید که  `run_in_executor()` خود thread اصلی را متوقف نمی‌کند: تنها به اجراکننده تسکی می‌دهد تا اجرا کند (یک شئ از جنس Future برمی‌گرداند، بدان معنا که می‌توانید در صورتی که در یک تابع coroutine دیگر فراخوانی شود، منتظر نتیجه‌ی آن بمانید). کار اجراکننده فقط زمانی شروع می‌شود که `run_until_complete()`، که اجازه می‌دهد event loop شروع به کار کند، فراخوانی شود.
</li>
<li>
نکته‌ای دیگر بر مورد دوم: مجموعه‌ی تسک‌های در انتظار اجرا، شامل جایی برای فراخوانی blocking() در run_in_executor نیست. این موضوع شامل هر فراخوانی که به جای Task، شئ Future برمی‌گرداند، صادق است. مستندات اصلی کیفیت نسبتا خوبی در تمییز میان تایپ اشیای بازگردانی‌شده دارد، و می‌توانید تایپ شئ بازگردانی‌شده را آن‌جا ببینید؛ تنها به یاد داشته باشید که all_tasks() فقط و فقط Task برمی‌گرداند و نه Future.
</li>
</ol>

خروجی زیر مربوط به اجرای مثال قبل است:

```shell
$ python quickstart_exe.py
Sun Aug 18 01:20:42 2019 Hello!
Sun Aug 18 01:20:43 2019 Hello from a thread!
Sun Aug 18 01:20:43 2019 Goodbye!
```

حال که موارد اصلی asyncio برای استفاده‌ی توسعه‌دهندگان end-user را آموختید، زمان آن فرارسیده که دامنه‌ی یادگیری خود را گسترش دهیم و asyncio API را در قالب یک سلسله مراتب بیان کنیم. این کار، فهم استفاده‌ی بهینه از مستندات را آسان‌تر می‌کند.

## بیان سلسله مراتبی Asyncio

همان‌طور که در بخش قبل دیدید، تنها نیاز است بخشی از دستورات asyncio را برای کار با آن به عنوان توسعه‌دهنده‌ی end-user بدانید. متاسفانه، مستندات این کتاب‌خانه تعداد زیادی API را معرفی می‌کند و این کار را چنان بدون دسته‌بندی انجام می‌دهد که دشوار است بتوان گفت که چه چیزهایی برای استفاده‌ی روزمره است و چه چیزهایی برای استفاده‌ی طراحان فریم‌ورک.

طراحان فریم‌ورک که همین مستندات را مطالعه می‌کنند، به دنبال نقاط اتصالی هستند که بتوانند به آن‌ها، فریم‌ورک‌های جدید یا کتاب‌خانه‌های شخص ثالث خود را متصل کنند. در این بخش، از دید یک طراح فریم‌ورک به asyncio می‌نگریم تا حسی از مسیر ساخت یک کتاب‌خانه‌ی سازگار با async پیدا کنیم. امیدواریم که این کار، توضیحات بیشتری برای مواردی که در کار به آن‌ها نیاز پیدا می‌کنید، باشد.

بر اساس این دیدگاه،، خوب است که ماژول asyncio را، به جای یک لیست بدون دسته‌بندی، در قالب یک سلسله مراتب ببینیم، که در آن هر سطح، بر پایه‌ی مواردی از سطح پایین‌تر از خود ساخته می‌شود. البته این دسته‌بندی چندان هم با نظم و ترتیب نیست و من قدری سلیقه‌ی شخصی را نیز در آن دخالت داده‌ام. اما امیدوارم این سلسله مراتب، دید دیگری از ای‌پی‌آی asyncio به شما بدهد.

جدول 3-1، و نام‌ها و مراتب آن، تماما ساخته‌ی من است و تنها برای ساختارمندتر کردن توضیح‌دادن asyncio است. خواننده‌ی متبحر ممکن است موارد را به ترتیب دیگری دسته‌بندی کند. ایرادی بر آن وارد نیست!

جدول 3-1: موارد موجود در asyncio در قالب یک سلسله‌مراتب، برای توسعه‌دهندگان end-user.
Level | Concept | Implementation |
--- | --- | --- |
**Tier 9** | **Network: streams** | StreamReader, StreamWriter, asyncio.open_connection(), asyncio.start_server() |
Tier 8 | Network: TCP & UDP | Protocol|
Tier 7 | Network: transports| BaseTransport|
**Tier 6** | **Tools** | asyncio.Queue|
**Tier 5** | **Subprocesses & threads** | run_in_executor(), asyncio.subprocess|
Tier 4 | Tasks | asyncio.Task, asyncio.create_task()|
Tier 3 |Futures | asyncio.Future|
**Tier 2** |**Event loop**| asyncio.run(), BaseEventLoop|
**Tier 1 (Base)** |**Coroutines**| async def, async with, async for, await|

در بنیادی‌ترین سطح، سطح 1، ما coroutine هایی را داریم که تا کنون در این کتاب دیده‌اید. این‌جا پایه‌ای‌ترین سطحی است که می‌توان از آن برای طراحی یک فریم‌ورک شخص ثالث شروع به کار کرد. به طرز جالبی، این بخش برای نه یک، که دو فریم‌ورک async موجود، [Curio](https://github.com/dabeaz/curio) و [Trio](https://github.com/python-trio/trio). هر دوی این‌ها تنها برا coroutine های خود پایتون تکیه دارند و از چیزی در asyncio استفاده نمی‌کنند.

سطح بعدی، حلقه‌های event هستند. Coroutine ها به خودی خود استفاده‌ای ندارند: آن‌ها بدون حلقه‌ای که ازشان برای اجرا استفاده کند، کاری نمی‌کنند (بنابراین، Curio و Trio حتما حلقه‌های event خود را پیاده کرده‌اند). Asyncio نوعی از حلقه به نام `AbstractEventLoop` و یک پیاده‌سازی از آن به نام ‌`BaseEventLoop` را در خود دارد.

جداسازی صریح میان نوع و پیاده‌سازی این امکان را برای توسعه‌دهندگان [نرم‌افزارهای] شخص ثالث فراهم می‌کنند که بتوانند پیاده‌سازی‌های جایگزینی از حلقه‌های event انجام دهند. این کار در پروژه‌ی uvloop انجام شده‌است. حلقه‌ی event دراین پروژه، بسیار از حلقه‌ی استاندارد asyncio سریع‌تر است. مهم این که، [uvloop](https://github.com/MagicStack/uvloop) تنها نفوذی در این سطح‌بندی انجام داده و بخش حلقه‌ی آن را تغییر می‌دهد. امکان ایجاد چنین تغییراتی، دقیقا دلیل طراحی این چنینی asyncio با جداسازی‌های صریح میان اجزای محرک است.

سطح‌های 3 و 4 تسک‌ها و future ها را معرفی می‌کنند. این دو بسیار به هم مرتبطند؛ جدایی آن‌ها به دلیل زیرکلاس بودن Task برای Future است، اما این دو به راحتی می‌توانند در یک سطح به حساب بیایند. یک شی از نوع Future نماینده‌ی یک کار در حال اجرا است که از طریق اعلان، نتیجه‌ی خود را در حلقه‌ی event برمی‌گرداند، در حالی که یک Task نماینده‌ی یک coroutine است که روی حلقه‌ی event در حال اجراست. کوتاه‌تر بگوییم، Future «حلقه‌محور» است، در حالی که Task هم حلقه‌محور و هم «coroutineمحور» است. به عنوان یک توسعه‌دهنده‌ی end-user، بیش از آن که با futureها کار کنید، با Taskها کار خواهیدکرد، اما اگر طراح فریم‌ورک باشید، نسبت استفاده از این دو، بسته به جزئیات، فرق می‌کند.

سطح 5 نمایان‌گر ابزارهای مورد نیاز برای اجرا و انتظار برای اتمام کاری است که در یک thread یا حتی پروسه‌ی جداگانه در حال انجام است.

سطح 6 ابزارهای asyncمحور بیشتری مانند asyncio.Queue را معرفی می‌کند. این سطح را می‌توانستم پس از سطح شبکه قرار دهم، اما فکر می‌کنم که منظم‌تر است ابتدا تمام APIهای coroutineمحور را پیش از مواجهه با لایه‌های I/O یاد بگیریم. Queue ای که asyncio ارائه می‌دهد، APIای مشابه صف thread-safe در ماژول queue دارد، با این تفاوت که در asyncio برای متدهای get() و put() کلیدواژه‌ی async را در ابتدایشان لازم دارد. نمی‌توان از queue.Queue مستقیما درون coroutine ها استفاده کرد، چرا که متد get() آن thread اصلی را متوقف می‌کند.

و درنهایت، سطوح 7تا9 را که متعلق به ورودی و خروجی‌های شبکه هستند، داریم. به عنوان یک توسعه‌دهنده‌ی end-user، مطمئن‌ترین API برای کار با آن، streams API در سطح 9 است. من streams API را در بالاترین سطح از نظر انتزاع [و ساده‌تر برای فهم] قرار داده‌ام. protocols API، که دقیقا در یک سطح پایین‌تر از آن قرار دارد (سطح 8)، API پرجزئیات‌تری است؛ می‌توانید از protocols به جای streams استفاده کنید، اما استفاده از streams ساده‌تر است. سطح آخر I/Oی شبکه، سطح انتقال (transport) است (سطح 7). احتمال این‌که شما مستقیما با آن کار کنید، کم است، مگر این که بخواهید فریم‌ورکی برای استفاده‌ی آزاد بسازید و نیاز باشد چگونگی تنظیم انتقالات را درست کنید.

در «شروع سریع»، صفحه22، کمترین چیزهایی که برای شروع به کار با کتاب‌خانه‌ی asyncio نیاز است را مشاهده کردیم. حال که نگاهی به کلیت اجزای این کتاب‌خانه انداختیم، خوب است که لیست مجتمعی از ویژگی‌های آن را مرور کنیم و بر بخش‌هایی که احتمالا نیاز دارید یاد بگیرید، تاکید کنیم.

این موارد مهم‌ترین‌ها در یادگیری استفاده از کتاب‌خانه‌ی asyncio برای نوشتن برنامه‌های شبکه هستند:

سطح 1

<ul>
<li>
درک چگونگی نوشتن توابع async و استفاده از await برای فراخوانی و اجرای coroutine ها اهمیت دارد. 
</li>
</ul>
سطح 2
<ul>
<li>درک چگونگی بالاآوردن، از کار انداختن و کار کردن با حلقه‌ی event اهمیت دارد. </li>
</ul>
سطح 5
<ul>
<li>
اجراکننده‌ها برای متوقف‌کردن کد در برنامه‌ی async شما نیازند، و واقعیت این است که بیشتر کتاب‌خانه‌های شخص ثالث هنوز با asyncio سازگار نیستند. مثالی خوب از این مورد، کتاب‌خانه‌ی ORM از پایگاه داده‌ی SQLAlchemy، که هنوز برای آن هیچ جایگزین بهتری که سازگار با asyncio باشد، موجود نیست. 
</li>
</ul>
سطح 6
<ul>
<li>
اگر نیاز دارید به coroutineهایی که حداقل یک بار و هر بار به مدت طولانی اجرا می‌شوند، داده ورودی بدهید، بهترین راه برای انجام آن، استفاده از asyncio.Queue است. این کار دقیقا مشابه استفاده از queue.Queue برای توزیع داده بین threadهاست. نسخه‌ی asyncioی آن از همان  API ای استفاده می‌کند که ماژول استاندارد queue، با این تفاوت که از coroutineها به جای متدهای متوقف‌کننده‌ای مانند get() استفاده می‌کند. 
</li>
</ul>
سطح 9
<ul>
<li>
ای‌پی‌آی streams ساده‌ترین راه برای مدیریت ارتباطات سوکت در شبکه است، و در این‌جاست که باید برای برنامه‌های شبکه ایده‌پردازی کنید. می توانید ببینید که مدیریت دقیق‌تری نیاز است، و بعد به protocols API تغییر مسیر دهید. اما در بیشتر پروژه‌ها بهتر است تا زمانی که بدانید چه مسئله‌ای را دارید حل می‌کنید، چیزها را ساده انجام دهید. 
</li>
</ul>

البته، اگر از کتاب‌خانه‌ی سازگار با asyncioی شخص ثالثی استفاده می‌کنید که تمام ارتباطات سوکت را برای شما مدیریت می‌کند - مانند aiohttp - نیازی نیست مستقیما با لایه‌های شبکه کار کنید. در این حالت، باید تکیه‌ی زیادی به مستندات ارائه‌شده برای کتاب‌خانه‌ی [مورد استفاده‌تان] داشته باشید.

در بخش‌های بعدی، بخش‌هایی که در بالا فهرست شده‌اند را با جزئیات بیشتری بررسی می‌کنیم.

سایت [pysheeet](https://www.pythonsheets.com/notes/python-asyncio.html) خلاصه‌ای عمیق (یا برگه تقلب) از بخش‌های کلی syncio ارائه کرده‌است؛ هر بخش کدی کوتاه به عنوان مثال دارد. این برگه بسیار پرجزئیات است و برای مبتدی‌ها پیشنهاد نمی‌شود، اما اگر تجربه‌ی برنامه‌نویسی پایتون دارید و از آن دسته افرادی هستید که اطلاعات جدید ارائه‌شده در قالب کد را سریع می‌گیرید، این سایت می‌تواند منبع خوبی باشد.

## متدهای Coroutine

از ابتدا شروع کنیم: coroutine چیست؟

هدف من در این بخش این است که معنی دقیق اصطلاحاتی مانند شئ coroutine و تابع غیرهم‌زمان (asynchronous) را متوجه شوید. مثال‌های که در این‌جا می‌آیند، تعاملات سطح پایینی را نشان می‌دهند که معمولا در اکثر برنامه‌ها نیاز نیست؛ در عین حال، به فهم شما از بخش‌های بنیادی asyncio عمق می‌بخشند و یادگیری بخش‌های بعدتر را ساده‌تر می‌کنند.

مثال‌ها می‌توانند در مفسر پایتون نسخه 3.8 و حالت تعاملی اجرا شوند. از شما خواهش می‌کنم که آن‌ها را خود تایپ کنید، خروجی‌ها را مشاهده کنید، و در صورت امکان، با راه‌های مختلف تعامل با async و await بازی کنید.

ماژول asyncio اولین بار در نسخه 3.4 پایتون اضافه شد، اما دستور جدید برای coroutineها و async def و await در نسخه‌ی 3.5 اراده شدند. پیش از این، دیگران چگونه با asyncio کار می‌کردند؟ از generatorها به گونه‌ی مخصوصی استفاده می‌کردند که گویی coroutine اند! در مجموعه کدهای قدیمی‌تر، توابع generator را می‌بینید که دکوراتور `@asyncio.coroutine` را دارند و در آن‌ها yield from به کار رفته‌است. coroutineهایی که با async def ساخته شده‌اند، به عنوان اصل مبنا قرار می‌گیرند، چرا که در زبان تنها به همین عنوان نوشته شده‌اند. در این کتاب، از پرداختن به coroutineهای generatorمحور قدیمی صرف نظر می‌شود.

## کلیدواژه‌ی جدید async def

مثال 3-4: توابع async تابعند و نه coroutine

```python
>>> async def f(): #1
...     return 123
...
>>> type(f) #2
<class 'function'>
>>> import inspect #3
>>> inspect.iscoroutinefunction(f) #4
True
```

<ol>
<li>
مثال بالا، ساده‌ترین راه ایجاد یک coroutine است: شبیه یک تابع عادی، با این تفاوت که با async def شروع می‌شود.
</li>
<li>
عجب! نوع دقیق f، یک coroutine نیست! بلکه تنها یک تابع معمولی است. با وجود این که رایج است به توابع async def، coroutine گفته شود، اما پایتون آن‌ها را «توابع» coroutine می‌بیند. کد بالا شبیه کارکرد توابع generator در پایتون است:
</li>

```python
>>> def g():
...     yield 123
...
>>> type(g)
<class 'function'>
>>> gen = g()
>>> type(gen)
<class 'generator'>
```

<li style="list-style-type: disc">
اگر چه g به غلط گاهی generator خوانده می‌شود، یک تابع می‌ماند و تنها در زمان اجرا generator بارگردانده می‌شود. توابع coroutine دقیقا همین طور کار می‌کنند: نیاز است تابع async def را برای دریافت شئ coroutine فراخوانی کنید.
</li>
</ol>
<ol start="3">
<li>
ماژول inspect در کتاب‌خانه‌ی استاندارد، ظرفیت‌های بهتری برای بررسی درونی برنامه‌ها نسبت به تابع توکار type() به دست می‌دهد. 
</li>
<li>
تابعی به نام iscoroutinefunction() وجود دارد که به شما این امکان را می‌دهد که تمایز بین یک تابع معمولی و یک coroutine را ببینید.
</li>
</ol>

مجدد به تابع async def خود، f() باز می‌گردیم. مثال 3-5 نشان می‌دهد که طی فراخوانی آن چه اتفاقی می‌افتد.

مثال 3-5. یک تابع async def، شیئی آز جنس coroutine برمی‌گرداند.

```python
>>> coro = f()
>>> type(coro)
<class 'coroutine'>
>>> inspect.iscoroutine(coro)
True
```

به سوال اصلی خود باز می‌گردیم: یک coroutine دقیقا چیست؟ شیئی است که امکان ادامه‌ی اجرای یک تابع پشت صحنه را که پیش از تکمیل کارش معلق شده‌است، فراهم می‌کند. آشنا به چشم آمدن این مفهوم به این دلیل است که coroutineها بسیار شبیه به generator عمل می‌کنند. البته که، پیش از معرفی coroutine های فعلی و کلیدواژه‌های async def و await در پایتون 3.5، این امکان وجود داشت که از کتاب‌خانه‌ی asyncio با استفاده از generator های رایج و دکوراتورهای مخصوص استفاده کرد. جای تعجب ندارد که توابع جدید async def (و coroutine هایی که برمی‌گردانند)، مشابه generator ها رفتار کنند.

می‌توان قدری بیشتر با اشیاء coroutine بازی کرد تا بهتر بتوان درک کرد که پایتون چگونه از آن‌ها استفاده می‌کند. مهم‌ترین موضوع این است که، می‌خواهیم ببینیم پایتون چگونه بین اجراهای coroutineهای مختلف رفت و آمد می‌کند. ابتدا به چگونگی حاصل شدن مقدار برگشتی می‌نگریم.

زمانی که یک coroutine مقداری را برمی‌گرداند، آن‌چه واقعا اتفاق می‌افتد، ایجادشدن یک استثنای StopIteration است. مثال 3-6، که در همان چارچوب مثال‌های قبلی ادامه می‌یابد، این موضوع را آشکار می‌کند.

مثال 3-6. درون یک coroutine: استفاده از send() و StopIteration

```python
>>> async def f():
...     return 123
>>> coro = f()
>>> try:
...     coro.send(None) #1
... except StopIteration as e:
...     print('The answer was:', e.value) #2
...
The answer was: 123
```

<ol>
<li>
یک coroutine با ارسال شیئی از جنس None به آن، ایجاد می‌شود. پشت صحنه، این، کاری است که حلقه‌ی event با coroutine ها انجام می‌دهد؛ شما هرکز نیازی نخواهید داشت که آن را دستی انجام دهید. تمام coroutineهایی که می‌سازید یا با loop.create_task(coro) یا await coro اجرا می‌شود. این حلقه‌ی event است که پشت صحنه، send(None) را اجرا می‌کند. 
</li>
<li>
زمانی که coroutine مقداری را برمی‌گرداند، نوع خاصی از استثنا به نام StopIteration ایجاد می‌شود. دقت کنید که می‌توان به مقدار بازگردانده شده از طریق متغیر value ی استثنا دسترسی داشت. این‌جا هم، نیازی به دانستن این کارکردها نیست: از دید شما، توابع async def مقداری را با دستور return، مانند توابع عادی، باز می‌گردانند.
</li>
</ol>

این دو نکته، send() و StopIteration، شروع و پایان coroutine در حال اجرا را تعریف می‌کنند. تا این‌جا، به نظر می‌آید که این روش اجرای توابع بسیار پیچیده است، اما مسئله‌ای نیست: حلقه‌ی event مسئول اجرای coroutine با دستورات درونی گفته‌شده است. از دید شما، coroutine ها فقط برای اجرا در حلقه برنامه‌ریزی شده و به صورت بالا به پایین، تقریبا شبیه توابع معمولی، اجرا می‌شوند.

قدم بعدی آشنایی با معلق کردن اجرای یک coroutine است.

## کلیدواژه‌ی جدید await

این کلیدواژه همواره یک پارامتر می‌گیرد و تنها چیزی را قبول می‌کند که awaitable باشد. یک awaitable دقیقا یکی از دو مورد زیر است:

<ul dir="rtl">
<li>
یک coroutine (یا به عبارت دیگر، نتیجه‌ی فراخوانی تابع async def)
</li>
<li>
هر شیئی که متد انحصاری await() را پیاده‌سازی کند. این متد انحصاری باید یک پیمایش‌گر (iterator) بازگرداند. 
</li>
</ul>

توضیحات مربوط به نوع دوم از بحث این کتاب خارج است (هرگز در برنامه‌نویسی روزمره‌ی asyncio به آن نیازی پیدا نمی‌کنید)، اما نوع اول، همان‌طور که در مثال 3-7 آمده، بسیار سرراست است.

مثال 3-7. استفاده از await بر سر یک coroutine

```python
async def f():
    await asyncio.sleep(1.0)
    return 123
async def main():
    result = await f() #1
    return result
```

<ol dir="rtl">
<li>
فراخوانی f() یک coroutine ایجاد می‌کند؛ این بدان معناست که می‌توانیم آن را await کنیم (به انتظار اجرای آن بنشینیم). مقدار متغیر result پس از اتمام اجرای f()، 123 خواهدبود.
</li>
</ol>

پیش از خاتمه‌ی این بخش و شروع توضیحات event loop سودمند است که ببینیم چگونه می‌توان به coroutine ها استثنا خوراند. این مورد بسیار در متوقف‌سازی استفاده می‌شود: زمانی که task.cancel() را فراخوانی می‌کنید، حلقه‌ی event پشت صحنه coro.throw() را استفاده کرده تا asyncio.CancelledError را درون coroutine ایجاد کند (مثال 3-8).

مثال 3-8. استفاده از coro.throw() برای تزریق استثنا در یک coroutine

```python
>>> coro = f() #1
>>> coro.send(None)
>>> coro.throw(Exception, 'blah') #2
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
 File "<stdin>", line 2, in f
Exception: blah
blah
```

<ol>
<li>
مانند قبل، یک coroutine جدید از f()، تابع coroutine، ساخته می‌شود.
</li>
<li>
به جای یک send() دیگر، throw() را فرامی‌خوانیم و یک کلاس استثنا و یک مقدار ایجاد می‌کنیم. این کار یک استثنا درون coroutine و در نقطه‌ی await ایجاد می‌کند. 
</li>
</ol>

متد throw() در درون asyncio برای متوقف‌کردن تسک استفاده می‌شود. این را به سادگی نشان خواهیم داد. در مثال 3-9 حتی از این هم فراتر خواهیم رفت و استثنای ایجادشده را درون یک coroutine جدید مدیریت می‌کنیم.

```python
>>> import asyncio
>>> async def f():
...     try:
...         while True: await asyncio.sleep(0)
...     except asyncio.CancelledError: #1
...         print('I was cancelled!') #2
...     else:
...         return 111
>>> coro = f()
>>> coro.send(None)
>>> coro.send(None)
>>> coro.throw(asyncio.CancelledError) #3
I was cancelled! #4
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
StopIteration #5
```

<ol>
<li>
حال تابع coroutine ما یک استثنا را مدیریت می‌کند. در واقع، استثنای منحصربه‌فردی را مدیریت می‌کند که در کتاب‌خانه‌ی asyncio برای متوقف‌کردن تسک‌ها استفاده می‌شود: asyncio.CancelledError. دقت کنید که استثنا از بیرون به coroutine تزریق می‌شود (از طریق event loop، که با آن هم‌چنان در حال شبیه‌سازی دستی توابع send() و throw() هستیم). در کد واقعی، که جلوتر خواهیددید، CancelledError در زمان متوقف‌شدن تسک‌ها درون coroutine داخل یک تسک ایجاد می‌شود.
</li>
<li>
این خط پیامی ساده است برای اطلاع‌رسانی توقف تسک. دقت کنید که با مدیریت استثنا، مطمئن می‌شویم که دیگر پیش نرفته و coroutine مقداری را بازمی‌گرداند. 
</li>
<li>
در این‌جا استثنای CancelledError را throw() می‌کنیم. 
</li>
<li>
مطابق انتظار، می‌بینیم که پیام مربوط به توقف نوشته می‌شود.
</li>
<li>
تابع coroutine به صورت صحیحی تمام می‌شود (به یاد آورید که استثنای StopIteration طریق معمول اتمام کار coroutine هاست).
</li>
</ol>

برای رساندن این نکته به سرمنزل مقصود، که «متوقف‌سازی تسک» چزی بیشتر از ایجاد و مدیریت عادی استثناها نیست، مثال 3-10 را ببینید، که در آن متوقف‌سازی را پله کرده و به coroutine دیگری منتقل می‌شویم.

مثال 3-10. فقط به جهت آموزش - این کار را انجام ندهید!

```python
>>> async def f():
...     try:
...         while True: await asyncio.sleep(0)
...     except asyncio.CancelledError:
...         print('Nope!')
...         while True: await asyncio.sleep(0) #1
...     else:
...         return 111
>>> coro = f()
>>> coro.send(None)
>>> coro.throw(asyncio.CancelledError) #2
Nope!
>>> coro.send(None) #3
```

<ol>
<li>
به جای نوشتن یک پیام، چه اتفاقی می‌افتد اگر پس از متوقف‌سازی، به عقب برگردیم و منتظر یک awaitable دیگر بمانیم؟
</li>
<li>
جای تعجب ندارد که، coroutine بیرونی به حیات ادامه داده و بلافاصله دوباره در coroutine جدید معلق می‌شود. 
</li>
<li>
همه چیز عادی صورت می‌گیرد و coroutine مطابق انتظار معلق می‌شود و به کار ادامه می‌دهد. 
</li>
</ol>

البته، شایان ذکر است که هرگز نباید چنین کنید! اگر coroutine شما یک سیگنال متوقف‌شدن دریافت کند، دستوری واضح دریافت کرده که تنها پاک‌سازی‌های لازم را انجام داده و تمام شود. به این بی‌توجهی نکنید!

تا به این‌جا، بسیار خسته‌کننده است که با فراخوانی دستی .send(None) نقش یک حلقه‌ی event را بازی کنید. بنابراین در مثال 3-11، حلقه‌ی event موجود در asyncio را به کار گرفته و مثال قبلی را قدری تمیزتر ارائه می‌کنیم.

```python
>>> async def f():
...     await asyncio.sleep(0)
...     return 111
>>> loop = asyncio.get_event_loop() #1
>>> coro = f()
>>> loop.run_until_complete(coro) #2
111
```

<ol>
<li>
یک حلقه ایجاد کنید.
</li>
<li>
تابع coroutine را تا سرانجامش اجرا کنید. پشت صحنه، تمام .send(None) ها برای ما فراخوانی می‌شود و اتمام coroutine را با استثنای StopIteration که مقدار بازگشتی را در خود دارد، شناسایی می‌کند.
</li>
</ol>

## حلقه‌ی event

در بخش قبل نشان دادیم که متدهای send() و throw() چگونه با یک coroutine تعامل می‌کنند، اما تنها برای این بود که متوجه شود خود coroutineها چگونه ساختار یافته‌اند. حلقه‌ی event در asyncio تمام جابه‌جایی‌ها بین coroutine ها را، به همراه به دام انداختن استثناهای StopIteration و موارد بیشتری چون گوش‌کردن به سوکت‌ها و فایل دیسکریپتورها برای eventها، مدیریت می‌کند.

شما می‌تواند بدون کارکردن مستقیم با event loopها به کار خود برسید: کد asyncioی شما می‌تواند تماما با استفاده از فراخوانی‌های `await` که با `asyncio.run(coro)` ایجاد می‌شود، نوشته‌شود. با این حال، گاهی درجاتی از تعامل با event loop نیاز است، و در این بخش توضیح می‌دهیم که چگونه حلقه را ایجاد کنید.

دو راه داریم:

_**پیشنهادی**_

> استفاده از `asyncio.get_running_loop()`، که در بدنه coroutine قابل فراخوانی باشد

_**غیرپیشنهادی**_

> استفاده از `asyncio.get_event_loop()`، از هرجا قابل فراخوانی باشد

راه غیرپیشنهادی را در بسیاری از کدها می‌توان دید، چرا که تابع جدیدتر `get_running_loop()` بسیار بعدتر، در پایتون 3.8 معرفی شد. بنابراین، سودمند است که در عمل ایده‌ای از کارکرد روش غیرپیشنهادی داشته باشیم. با مثال 3-12 شروع می‌کنیم.

مثال 3-12. دریافت همان حلقه‌ی event اولیه در هرزمان

```python
>>> loop = asyncio.get_event_loop()
>>> loop2 = asyncio.get_event_loop()
>>> loop is loop2 #1
True
```

<ol>
<li>
هر دو شناسه، loop و loop2، به یک شئ اشاره می‌کنند.
</li>
</ol>

این بدان معناست که اگر درون یک تابع coroutine باشید و نیاز به دسترسی به حلقه داشته باشید، می‌توانید `get_event_loop()‍` را فراخوانی کنید. نیازی به انتقال واضح یک پارامتر حلقه به تمام توابع خود نداریم.

شرایط در صورتی که طراح فریم‌ورک باشید فرق می‌کند: بهتر است صرفا جهت جلوگیری از شرایطی که در آن، کاربران کاری غیر معمول با [سیاست‌های event loop](https://docs.python.org/3/library/asyncio-policy.html#asyncio-policies) انجام دهند، توابع خود را به گونه‌ای طراحی کنید که یک پارامتر حلقه بپذیرند. این سیاست‌ها از بحث این کتاب خارج هستند و چیز بیشتری در باره‌ی آن‌ها گفته نخواهدشد.

پس اگر `get_event_loop()` و `get_running_loop()` مانند هم کار می‌کنند، چرا هر دوی آن‌ها را داریم؟ چرا که `get_event_loop()` تنها در حوزه‌ی یک thread کار می‌کند. در واقع،‌ `get_event_loop()` در یک thread جدید کار نمی‌کند، مگر این که یک حلقه‌ی جدید با `new_event_loop()` ایجاد کنید و این حلقه‌ی جدید را برای آن thread با `set_event_loop()` تنظیم کنید. بیشتر ما تنها به یک حلقه و یک thread نیاز داریم. thread که آن را در بر بگیرد، نیاز داریم (در واقع، خواستار آنیم!).

در مقابل، `get_running_loop()` (متد پیشنهادی) همیشه کاری را که از آن انتظار می‌رود انجام می‌دهد، چرا که آن را تنها می‌توان در چارچوب یک coroutine، یا یک تسک، یا تابعی که این دو فرابخوانند، می‌توان فراخواند. همیشه حلقه‌ی در حال اجرای فعلی را برمی‌گرداند که تقریبا همان مطلوب ماست.

معرفی `get_running_loop()` هم‌چنین، ایجاد تسک‌های پشت صحنه را ساده‌تر کرده‌است. مثال 3-13 را در نظر بگیرید: این مثال شامل یک تابع coroutine است که درون آن تسک‌های اضافه‌ای ایجاد شده که در صف انتظار قرار نگرفته‌اند.

مثال 3-13. ایجاد تسک

```python
async def f():
    # Create some tasks!
    loop = asyncio.get_event_loop()
for i in range():
    loop.create_task(<some other coro>)
```

در مثال بالا، می‌خواهیم تسک‌های کاملا جدیدی درون coroutine استفاده کنیم. با قرار ندادن آن‌ها در صف انتظار، اطمینان حاصل می‌شود که آن‌ها مستقل از چارچوب اجرای تابع f()، یک coroutine، اجرا می‌شوند. در واقع، f() پیش از اتمام تسک‌هایی که ایجاد کرده، خاتمه می‌یابد.

پیش از پایتون 3.7، مهم بود که ابتدا حلقه را برای برنامه‌ریزی یک تسک ساخت، اما با معرفی get_running_loop()، دیگر توابع asyncio مانند asyncio.create_task() برای استفاده از آن به میدان آمدند. پس از پایتون 3.7 تا به الان، کدی که یک تسک async را می‌سازد به شکل زیر است:

```python
import asyncio
async def f():
    # Create some tasks!
    for i in range():
        asyncio.create_task(<some other coro>)
```

این امکان نیز وجود دارد که تابع سطح پایین دیگری به نام `asyncio.ensure_future()` را به کار گرفت تا تسک‌ها را مشابه create_task() بسازد. این صورت را هم‌چنان در کدهای قدیمی‌تر asyncio می‌توان دید. من به این فکر می‌کردم که از توضیح `ensure_future()` صرف نظر کنم، اما این مورد، بهترین مثال است که نشان دهد asyncio تنها برای طراحان فریم‌ورک بوده، و سیاق سابق این ماژول را برای توسعه‌دهندگان اپلیکیشن سخت‌فهم کرده است. تفاوت میان `asyncio.create_task()` و `asyncio.ensure_feature` بسیار ریز است و برای بسیاری از مبتدیان گیج‌کننده است. این تفاوت‌ها را در بخش بعد بررسی می‌کنیم.


### تسک‌ها و Futureها
پیش‌تر به بررسی coroutineها و چگونگی اجرای آن‌ها در حلقه برای مفیدتر بودنشان پرداختیم. حال می‌خواهم مختصرا درباره APIهای تسک و Future صحبت کنم. موردی که بیش‌تر با آن سر و کار خواهید داشت تسک است، زیرا بیش‌تر کارهای شما شامل اجرای coroutineها با تابع `()create_task` است، دقیقا همانطور که در [بخش "آغاز سریع" در صفحه 22](#quickstart) آمده است.

یک راه ساده برای فکر کردن به آن به این صورت است: یک Future در واقع نشان‌دهنده‌ی حالت پایان future از یک فعالیت خاص بوده و توسط حلقه‌ مدیریت می‌شود. Task نیز دقیقا به همین صورت است، اما "فعالیت خاص" یک coroutine است - احتمالا یکی از coroutineهایی با استفاده از یک تابع async def  به اضافه‌ی `()create_task` ایجاد کرده‌اید.  

کلاس Future حالتی از چیزی را نشان می‌دهد که با یک حلقه‌ در تعامل است. این توضیحات بیش از حد مبهم بوده و نمی‌توانند مفید واقع شوند، برای همین می‌توانید به Future به عنوان یک کلید برای وضعیت کامل شدن فکر کنید. زمانی که یک instance از Future ساخته می‌شود، کلید روی حالت "هنوز کامل نشده" تنظیم می‌شود، اما در زمان دیگری "کامل" می‌شود. در حقیقت یک نمونه از Future یک متد به نام ()done دارد که به شما اجازه می‌دهد وضعیت را بررسی کنید. این مسئله در مثال 15-3 نشان داده شده است. 

مثال 15-3. بررسی وضعیت تکمیل شده با ()done

``` python
>>> from asyncio import Future
>>> f = Future()
>>> f.done()
False
```

همچنین یک instance از Future ممکن است کارهای زیر را نیز انجام دهد:

<ul>
<li>
داشتن یک مجموعه مقدار با نام "result" (از (value)set_default. برای مقداردهی، و از ()result برای به دست آوردن مقدار استفاده کنید)
</li>
</ul>
<ul>
<li>
کنسل شدن با تابع ()cancel. (و همچنین بررسی کنسل شدن با ()cancelled.)
</li>
</ul>
<ul>
<li>
داشتن توابع callback که در زمان کامل شدن future اجرا می‌شوند.
</li>
</ul>

با اینکه Taskها رایج‌تر هستند، نمی‌توانید به طور کامل از  Futureها اجتناب کنید: به طور مثال، اجرای یک تابع در یک اجراکننده یک instance از Future را بازمی‌گرداند، نه یک Task. بیاید نگاهی سریع به مثال 16-3 بیندازیم تا ببینیم مستقیما کار کردن با یک نمونه از Future چگونه است. 

مثال 16-3. تعامل با یک نمونه از Future


``` python
>>> import asyncio
>>>
>>> async def main(f: asyncio.Future): #1
...     await asyncio.sleep(1)
...     f.set_result('I have finished.') #2
...
>>> loop = asyncio.get_event_loop()
>>> fut = asyncio.Future() #3
>>> print(fut.done()) #4
False
>>> loop.create_task(main(fut)) #5 
<Task pending name='Task-1' coro=<main() running at <console>:1>>
>>> loop.run_until_complete(fut) #6
'I have finished.'
>>> print(fut.done())
True
>>> print(fut.result()) #7
I have finished.
```

<ol>
<li>
یک تابع main ساده ایجاد کنید. می‌توانیم این تابع را اجرا کنیم، کمی صبر کنیم، و سپس نتیجه را بر روی f که یک Future است ثبت کنیم.
</li>
<li>
result را مقداردهی کنید.
</li> 
<li>
به طور دستی یک نمونه از Future ایجاد کنید. توجه کنید که این نمونه به طور پیشفرض به حلقه‌ي ما گره خورده است، اما به هیچ coroutineی متصل نشده و نخواهد شد. (برای همین از Taskها استفاده می‌شود)
</li>
<li>
قبل از انجام هر کاری بررسی کنید که future هنوز به اتمام نرسیده باشد.
</li>
<li dir='rtl'>
coroutine ‍<code dir='rtl'>()main</code> را برنامه‌ریزی کنید و از future عبور کنید. به یاد داشته باشید، تمام کاری که coroutine <code dir='rtl'> ()main </code> انجام می‌دهد sleep و سپس تغییر وضعیت نمونه‌ی Future است. (توجه داشته باشید که coroutine <code dir='rtl'> ()main </code> هنوز شروع به اجرا نمی‌کند: coroutineها تنها زمانی اجرا می‌شوند که حلقه در حال اجرا باشد.)
</li>
<li>
در اینجا ما از <code>()run_until_complete</code> به جای یک instance از Task، بر روی یک instance از Future استفاده می‌کنیم. این کار با آنچه که قبلا دیده‌اید متفاوت است. حال که حلقه در حال اجرا است، coroutine <code dir='rtl'> ()main </code> شروع به اجرا خواهد کرد.
</li>
<li>
در نهایت،‌ Future زمانی که result آن مقداردهی شد کامل می‌شود. پس از کامل شدن، result قابل دسترسی خواهد بود. 
</li>
</ol>

البته بعید است که با Future مانند چیزی که در اینجا نشان داده شد به صورت مستقیم کار کنید؛ این نمونه کد تنها با اهداف آموزشی ارائه شده است. بیش‌تر ارتباط شما با `ayncio` از طریق instanceهایی از Task خواهد بود. 

ممکن است بخواهید بدانید با اجرای ()set_result بر روی نمونه‌ای از Task چه اتفاقی خواهد افتاد. انجام این کار پیش از Python 3.8 امکان‌پذیر بود، اما دیگر مجاز نیست. نمونه‌های Task در واقع wrapperهایی برای آبجکت‌های coroutine هستند، و مقادیر نتایج آن‌ها تنها به صورت داخلی و به عنوان نتیجه‌ی تابع coroutine که در لایه‌ی پایین‌تر قرار گرفته است ذخیره می‌شوند. این مسئله در مثال 17-3 نشان داده شده است.

مثال 17-3. فراخوانی ()set_result بر روی یک Task.

``` python
>>> import asyncio
>>> from contextlib import suppress
>>>
>>> async def main(f: asyncio.Future):
...     await asyncio.sleep(1)
...     try:
...         f.set_result('I have finished.') #2
...     except RuntimeError as e:
...         print(f'No longer allowed: {e}')
...         f.cancel() #3
...
>>> loop = asyncio.get_event_loop()
>>> fut = asyncio.Task(asyncio.sleep(1_000_000)) #1
>>> print(fut.done())
False
>>> loop.create_task(main(fut))
<Task pending name='Task-2' coro=<main() running at <console>:1>>
>>> with suppress(asyncio.CancelledError):
... loop.run_until_complete(fut)
...
No longer allowed: Task does not support set_result operation
>>> print(fut.done())
True
>>> print(fut.cancelled()) #3
True
```

<ol>
<li>
تنها تفاوت این است که به جای ساخت نمونه‌ای از Future، یک نمونه از Task ایجاد می‌کنیم. البته Task API از ما می‌خواهد که یک coroutine ارائه دهیم؛ ما فقط از ()sleep استفاده می‌کنیم زیرا راحت‌تر است.
</li>
<li>
یک instance از Task پاس داده می‌شود. این کار منطبق با امضای نوع تابع نیز هست (زیرا Task یک زیرکلاس از Future است)، اما از Python 3.8 به بعد دیگر مجاز به فراخوانی ()set_result بر روی یک Task نیستیم: اقدام به انجام این کار موجب RuntimeError خواهد شد. ایده این است که یک  Task نشان‌دهنده‌ی یک coroutine در حال اجرا است، پس result باید همیشه از آن به دست آید. 
</li>
<li>
با این وجود همچنان می‌توانیم یک Task را ()cancel کنیم. انجام این کار موجب بروز CancelledError داخل coroutineهای داخلی خواهد شد.
</li>
</ol>

### ایجاد یک Task؟ اطمینان از یک Future؟ تصمیم خود را بگیرید

در بخش ["آغاز سریع"](#quickstart) در صفحه‌ی 22، گفتم که روش اجرای coroutineها استفاده از `()asnycio.create_task` است. پیش از آنکه این تابع معرفی شود، ضروری بود که یک instance از حلقه را به دست آورده و از ()loop.create_task برای انجام همین کار استفاده کنیم. انجام این کار با استفاده از یک تابع ماژولار نیز ممکن است: `()asyncio.ensure_future`. برخی از توسعه‌دهندگان استفاده از ()create_task را توصیه کرده‌اند، در حالی که برخی دیگر استفاده از ()ensure_task را توصیه می‌کنند.

در طول تحقیقاتم برای این کتاب،‌ متقاعد شدم که متد API ‍<code dir='rtl'>()asyncio.ensure_task</code> مسئول سوءتفاهم‌های گسترده‌ای در مورد کتابخانه‌ی asyncio است. بخش زیادی از API تقریبا واضح است، اما چند مانع بد برای یادگیری نیز وجود دارد، که این مورد نیز یکی از این موانع است. هنگامی که با `()ensure_task` روبرو می‌شوید، مغز شما به سختی تلاش می‌کند که آن را در مذل ذهنیتان از نحوه‌ی استفاده از asyncio ادغام کند، و احتمالا هم شکست می‌خورد! 

مشکل `()ensure_task` با این توضیح از [داکیومنت Python 3.6 asyncio](https://python.readthedocs.io/en/stable/library/asyncio-task.html) مشخص شده است:

`asyncio.ensure_future(coro_or_future, *, _loop=None)`

> اجرای یک شئ از coroutine را برنامه‌ریزی کنید: آن را در یک future قرار دهید. یک شئ از Task بازگردانید. اگر آرگومان یک Future است، به صورت مستقیم بازمی‌گردد. 

بله؟! وقتی برای اولین بار این بخش را خواندم بسیار گیج‌کننده بود. بیاید یک توضیح شفاف‌تر از `()ensure_task` را بخوانیم:

<ul>
<li>
اگر یک coroutine را به این تابع پاس دهید، یک instance از Task ایجاد خواهد شد (و coroutine شما برای اجرا در حلقه‌ی رویداد برنامه‌ریزی خواهد شد). انجام این کار دقیقا مانند فراخوانی <code>()asyncio.create_task</code> (یا <code>()loop.create_task</code>) و بازگرداندن instance جدید Task است. 
</li>
</ul>
<ul>
<li>
اگر یک instance از Future را به این تابع پاس دهید (یا یک instance از Task، زیرا Task زیرکلاسی از Future است) همان چیزی که به تابع پاس داده‌اید را بدون هیچ تغییری دریافت خواهید کرد!
</li>
</ul>
این تابع یک مثال عالی برای بیان تفاوت میان asyncio API که برای توسعه‌دهندگان کاربران نهایی (API سطح بالا) و asyncio API که برای طراحان فریمورک‌ها (API سطح پایین) در دسترس هستند می‌باشد. بیاید نگاهی نزدیک‌تر به شیوه‌ی کار آن در مثال 18-3 داشته باشیم.

مثال 18-3. نگاهی نزدیک‌تر به شیوه‌ی کار ()ensure_task

``` python
import asyncio

async def f(): #1
 pass

coro = f() #2
loop = asyncio.get_event_loop() #3

task = loop.create_task(coro) #4
assert isinstance(task, asyncio.Task) #5

new_task = asyncio.ensure_future(coro) #6
assert isinstance(new_task, asyncio.Task)

mystery_meat = asyncio.ensure_future(task) #7
assert mystery_meat is task #8
```

<ol>
<li>
یک تابع coroutine ساده که هیچ کاری انجام نمی‌دهد. ما تنها به چیزی نیاز داریم که بتواند یک coroutine ایجاد کند.
</li>
<li>
با فراخوانی مستقیم تابع یک شئ coroutine ایجاد می‌کنیم. کم پیش می‌آید که برنامه‌ی شما چنین کاری انجام دهد، اما من می‌خواهم در اینجا (چند خط پایین‌تر) به صراحت بگویم که ما یک شئ از coroutine را به هر یک از توابع ()create_task و ()ensure_task ارسال می‌کنیم.
</li>
<li>
حلقه ی رویداد را بگیرید.
</li>
<li>
پیش از هر چیز، برای برنامه‌ریزی کردن coroutine خود در حلقه از ()loop.create_task استفاده می‌کنیم، و یک instance از Task را دریافت می‌کنیم.
</li>
<li>
نوع مقدار بازگشتی را بررسی می‌کنیم. تا اینجا چیز جالبی وجود ندارد.
</li>
<li>
نشان می‌دهیم که ()asyncio.ensure_task می‌تواند برای انجام همان کاری که ()create_task انجام می‌دهد مورد استفاده قرار گیرد: یک coroutine را به تابع دادیم و یک instance از Task دریافت کردیم (و coroutine نیز برای اجرا در حلقه برنامه‌ریزی شد)! اگر یک coroutine را به تابع پاس می‌دهید، هیچ تفاوتی میان ()loop.create_task و ()asyncio.ensure_future وجود ندارد. 
</li>
<li>
اما اگر یک instance از Task را به ()ensure_future ارسال کنیم چه اتفاقی می‌افتد؟ توجه داشته باشید که ما نمونه‌ای از Task را ارسال می‌کنیم که پیش‌تر توسط ()loop.create_task در مرحله 4 ساخته شده بود. 
</li>
<li>
دقیقا همان Task instance که ارسال کرده بودیم را دریافت می‌کنیم: بدون هیچ تغییری.
</li>
</ol>

ارسال مستقیم instanceهایی از Future چه فایده‌ای دارد؟ و چرا باید دو کار متفاوت را با استفاده از تابعی یکسان انجام دهیم؟ پاسخ این است که `()ensure_task` برای استفاده‌ی نویسندگانِ فریمورک‌ها جهت ارائه‌ی APIها به توسعه‌دهندگانی که می‌توانند از هر دو نوع پارامتر استفاده کنند ارائه شده است. باور نمی‌کنید؟ این بخش که توسط BDFL سابق ارائه شده است را بخوانید:

> نکته ()ensure_task برای زمانی است که ممکن است چیزی داشته باشید که می‌تواند یک coroutine و یا یک Future باشد (دومی شامل یک Task نیز می‌باشد، زیرا Task زیرکلاسی از Future است)، و شما می‌خواهید بتوانید متدی را بر روی آن فراخوانی کنید که تنها برای Future تعریف شده است (احتمالا تنها مثال مفید تابع ()cancel است). هنگامی که از قبل یک Future (یا Task) باشد، هیچ کاری انجام نمی‌دهد؛ زمانی که یک coroutine باشد، آن را در یک Task قرار می‌دهد.

> اگر می‌دانید که یک coroutine در اختیار دارید و می‌خواهید آن را برنامه‌ریزی کنید، API صحیح برای استفاده ()create_task است. تنها زمانی که باید ()ensure_task را فراخوانی کنید وقتی است که می‌خواهید یک API ارائه دهید(مانند بسیاری از API های خودِ asyncio) که می‌تواند یک coroutine و یا یک Future را به عنوان ورودی پذیرفته و نیاز دارید کاری با آن انجام دهید که مستلزم داشتن یک Future است. 

—Guido van Rossum, [commenting](https://github.com/python/asyncio/issues/477#issuecomment-268709555) on [issue #477](https://github.com/python/asyncio/issues/477)

در مجموع، ()asyncio.ensure_task یک تابع کمکی است که برای طراحان فریمورک‌ها ارائه شده است. ساده‌ترین روش توضیح این مسئله،‌قیاس آن با تابعی بسیار رایج‌تر است، پس بیایید همین کار را انجام دهیم. اگر تجربه‌ی چندساله‌ی برنامه‌نویسی داشته باشید، ممکن است توابعی مشابه با تابع ()listify در مثال 19-3 را دیده باشید.

مثال 19-3. یک تابع کاربردی برای تبدیل اجباری ورودی به لیست

``` python
def listify(x: Any) -> List:
    """ Try hard to convert x into a list """
    if isinstance(x, (str, bytes)):
        return [x]
    try:
        return [_ for _ in x]
    except TypeError
        return [x]
```

این تابع تلاش می‌کند آرگومان را به لیست تبدیل کند، مهم نیست که ورودی چه باشد. این نوع توابع معمولا در APIها و فریمورک‌ها برای تبدیل اجباریِ ورودی به یک نوع داده خاص استفاده می‌شوند که می‌تواند اجرای کدهای بعدی را آسان‌تر کند. با استفاده از این تابع می‌توانید همیشه مطمئن باشید که پارامتر خروجی از `()listify` یک لیست است. 

اگر نام تابع `()listify` را به `()ensure_list` تغییر دهم، باید بتوانید تشابه با `()asyncio.ensure_future` را مشاهده کنید: این تابع تلاش می‌کند که آرگومان ورودی را به یک Future (یا زیرکلاسی از آن) تبدیل کند. این تابع یک تابع کاربردی است که زندگی را برای توسعه‌دهندگان فریمورک‌ها، و نه توسعه‌دهندگانی مانند من و شما، آسان‌تر می‌کند. 

در واقع، ماژول کتابخانه استاندارد asyncio از `()ensure_task` دقیقا به همین دلیل استفاده می‌کند. زمانی که بعدا به API نگاه کنید، در هر جایی که پارامتر تابعی را می‌بینید که تحت عنوان "شئ‌های قابل انتظار" توصیف شده است، احتمالا به طور داخلی از `()ensure_task` استفاده شده است که ورودی تابع به طور اجباری به نوعی خاص تبدیل شود. به طور مثال، تابع `()asyncio.gather` دارای امضای زیر است:

``` python
asyncio.gather(*aws, loop=None, ...)
```

پارامتر aws به معنای "اشیاء قابل انتظار" است، که شامل coroutineها، taskها و futureها می‌شود. به صورت داخلی تابع ()gather از ()ensure_future برای تبدیل اجباری نوع داده استفاده می‌کند: taskها و futureها دست‌نخورده باقی می‌مانند، در حالی که taskها برای coroutineها ایجاد می‌شوند.

نکته کلیدی در این بخش این است که به عنوان توسعه‌دهنده‌ی برنامه، هیچگاه نباید به استفاده از ()asyncio.ensure_future نیاز پیدا کنید. این تابع بیش‌تر ابزاری برای طراحان فریمورک‌ها است. اگر به برنامه‌ریزی یک coroutine در حلقه‌ی رویداد نیاز دارید، می‌توانید این کار را به صورت مستقیم و با استفاده از `()asyncio.create_task` انجام دهید. 

در بخش‌های بعدی به سراغ قابلیت‌های سطح زبان رفته و با asynchronous context-managerها شروع می‌کنیم.

### Async Context Managers: async with

پشتیبانی از coroutineها در context managerها به شکل غیرقابل انتظاری راحت است. این مسئله منطقی است، زیرا در بسیاری از موقعیت‌ها به منابع شبکه-مثلا اتصالات و connectionها- و باز و بسته شدن آن‌ها در یک محدوده‌ی تعریف‌ شده نیاز است. 

کلید درک async with فهم این مسئله است که عملکرد یک context manager توسط فراخوانی‌های متد هدایت می‌شود، و همچنین در نظر داشته باشید: اگر آن متدها توابع coroutine بودند چه؟ در واقع همانطور که در مثال 20-3 نشان داده شده است به همین شکل کار می‌کنند.


مثال 20-3. Async context manager

``` python
class Connection:
    def __init__(self, host, port):
        self.host = host
        self.port = port
    async def __aenter__(self): #1
        self.conn = await get_conn(self.host, self.port)
        return conn
    async def __aexit__(self, exc_type, exc, tb): #2
        await self.conn.close()
async with Connection('localhost', 9001) as conn:
    <do stuff with conn>
```

<ol>
<li>
‌به جای تابع ویژه‌ی <code> ()__enter__ </code> برای context managerهای همزمان، از تابع ویژه‌ی <code>()__aenter__</code> استفاده می‌شود. این متد ویژه باید یک متد async def باشد.
</li>
<li>
به همین ترتیب،‌ به جای <code>()__exit__</code> از <code>()__aexit__</code> استفاده می‌کنیم. پارامترهای این تابع دقیقا مانند تابع <code>()__exit__</code> هستند. این پارامترها در صورتی که خطایی در بدنه‌ی context manager رخ دهد مقداردهی می‌شوند.
</li>
</ol>

<img style="float: left;width:120px;height:120px" src="./images/1.png">

اینکه از asyncio در برنامه‌ی خود استفاده می‌کنید بدان معنا نیست که تمام context managerهایتان نیز باید مانند این نمونه‌ها  async باشند. این context managerها تنها در صورتی مفید هستند که بخواهید چیزی را داخل متدهای ورود و خروج await کنید. اگر هیچ کد ورودی و خروجی مسدودکننده‌ای وجود ندارد از context managerهای معمولی استفاده کنید. 

حال-بین خودمان باشد-من خیلی به استفاده از این نوع context managerها علاقمند نیستم، آن هم زمانی که دکوراتور شگفت‌انگیز contextmanager@ در ماژول کتابخانه استاندارد contextlib وجود دارد. همانطور که ممکن است حدس بزنید، یک ورژن ناهمزمان که `asynccontextmanager@` است نیز وجود دارد که می‌تواند ساخت context managerهای ناهمزمان را بسیار ساده‌تر کند. 

### استفاده از contextlib

این رویکرد مشابه استفاده از دکوراتور ‍‍`contextmanager@` در کتابخانه‌ی استاندارد contextlib است. برای جمع‌بندی، مثال 21-3 ابتدا نگاهی به روش مسدودکننده می‌اندازد.

مثال 21-3. روش مسدودکننده

``` python
from contextlib import contextmanager

@contextmanager #1
def web_page(url):
    data = download_webpage(url) #2
    yield data
    update_stats(url) #3

with web_page('google.com') as data: #4
    process(data) #5
```

<ol>
<li>
دکوراتور contextmanager@ یک تابع generator را به یک context manager تبدیل می‌کند.
</li>
<li>
این فراخوانیِ تابع (که برای این مثال درست کرده‌ام) به طرز مشکوکی مانند چیزی به نظر می‌رسد که بخواهد از یک رابط شبکه استفاده کند، که نسبت به کدهای "معمولی" CPU بسیار کندتر است. این context manager باید در یک thread اختصاصی استفاده شود؛ در غیر اینصورت، تمام برنامه در حین انتظار برای داده‌ها متوقف می‌شود.
</li>
<li>
تصور کنید هر زمان که داده‌ای را از یک URL پردازش می‌کنیم برخی از آمارها را به روزرسانی می‌کنیم، مانند تعداد دفعاتی که URL دانلود شده است. از منظر همزمانی، ما باید بدانیم که آیا این تابع شامل فعالیت‌های داخلی I/O مانند نوشتن در دیتابیس از طریق شبکه می‌شود یا نه. اگر همینطور است، استفاده از ()update_stats نیز یک فراخوانیِ مسدودکننده است. 
</li>
<li>
context manager ما در حال استفاده است. به طور ويژه توجه داشته باشید که چگونه فراخوانی شبکه (به ()download_webpage) داخل ساختار context manager پنهان شده است. 
</li>
<li>
این فراخوانیِ تابع، ()process، نیز می‌تواند مسدودکننده باشد. ما باید کاری که تابع انجام می‌دهد را بررسی کنیم، زیرا تفاوت میان چیزی که مسدودکننده یا غیرمسدودکننده باشد کاملا مشخص نیست. ممکن است این موارد باشد:
<ul>
<li>
بی‌ضرر و غیرمسدودکننده (سریع و محدود به CPU)
</li>
</ul>
<ul>
<li>
مسدودکننده خفیف (سریع و محدود به I/O، شاید چیزی مانند دسترسی سریع به دیسک، به جای I/O شبکه)
</li>
</ul>
<ul>
<li>
مسدودکننده (کند و محدود به I/O)
</li>
</ul>
<ul>
<li>
شیطانی (آهسته و محدود به CPU)
</li>
</ul>
</li>
</ol>

به خاطر سادگی در این مثال، بیاید تصور کنیم که فراخوانی ()process عملیاتی سریع، محدود به CPU و در نتیجه غیرمسدودکننده است. 

این روش در Python3.7 معرفی شد.

مثال 22-3. روش غیرمسدودکننده


``` python
from contextlib import asynccontextmanager

@asynccontextmanager #1
async def web_page(url): #2
    data = await download_webpage(url) #3
    yield data #4
    await update_stats(url) #5

async with web_page('google.com') as data: #6
    process(data)
```

<ol>
<li>
دکوراتور جدید <code>asynccontextmanager@</code> دقیقا به همان روش قبلی استفاده شده است.
</li>
<li>
البته لازم است که تابع generator با async def  تعریف شود
</li>
<li>
همانند قبل،‌ ابتدا داده را از URL دریافت می‌کنیم و سپس آن را در بدنه‌ی context manager در دسترس قرار می‌دهیم. من کلیدواژه‌ی await را نیز اضافه کرده‌ام، که نشان‌دهنده‌ی این است که coroutine اجازه می‌دهد حلقه‌ی رویداد عملیات‌های دیگر را نیز در زمانی که ما برای کامل شدن فراخوانی شبکه صبر می‌کنیم اجرا کند. 
<ul>
<li>
توجه داشته باشید که ما نمی‌توانیم به سادگی کلیدواژه‌ی await را به هر چیزی اضافه کنیم. این تغییر در واقع این مسئله را در بر دارد که ما می‌توانستیم خودِ تابع ()download_webpage را تغییر داده و آن را به coroutineی تبدیل کنیم که با کلمه‌ی کلیدی await سازگار است. 
برای زمان‌هایی که تغییر تابع میسر نیست، رویکرد دیگری لازم است که آن را در مثال بعدی بررسی می‌کنیم.
</li>
</ul>
</li>
<li>
همانند پیش، داده در بدنه‌ی context manager در دسترس قرار می‌گیرد. من در تلاشم که کد را ساده نگه دارم،‌برای همین کنترل‌کننده‌ی معمول try/finally  را حذف کرده‌ام. شما باید برای کنترل خطاهایی که در بدنه‌ی تماس‌گیرنده رخ می‌دهند این قسمت را نیز بنویسید. 
<ul>
<li>
توجه داشته باشید که این حضور yield است که یک تابع را به یک generator تبدیل می‌کند؛ حضور اضافیِ کلیدواژه‌ی async def چیزی است که این تابع را به یک تابع generator ناهمزمان تبدیل می‌کند. زمانی که این تابع فراخوانی شود، یک generator ناهمزمان بازگردانده می‌شود. ماژول بازرسی دو عملکرد دارد که می‌تواند این موارد را ازمایش کند: <code>()isasyncgenfunction</code> و <code>()isasyncgen</code> به ترتیب.
</li>
</ul>
</li>
<li>
در اینجا تصور کنید که کد داخل تابع ()update_status را نیز به گونه‌ای تغییر داده‌ایم که بتواند coroutine ایجاد کند. سپس می‌توانیم از کلیدواژه‌ی await استفاده کنیم، که می‌تواند در زمانی که برای کار مربوط به I/O منتظر می‌مانیم موجب یک context switch به حلقه‌ی رویداد شود. 
</li>
<li>
تغییر دیگری نیز برای استفاده از context manager مورد نیاز بود: نیاز داشتیم از async with به جای with استفاده کنیم. 
</li>
</ol>

امیدوارم این مثال نشان دهد که asynccontextmanager@ جدید کاملا مشابه با دکوراتور contextmanager@ است. 

در بخش‌های 3 و 5 اشاره کردم که تغییر برخی از توابع برای آنکه بتوانند coroutine بازگردانند واجب بود؛ این توابع ()update_stats و ()download_webpage بودند. انجام این کار معمولا به این راحتی نیست،‌ زیرا پشتیبانی از async نیز باید به لایه‌های سوکت اضافه شود. 
تمرکز این مثال بیش‌تر بر روی استفاده از دکوراتور asynccontextmanager@ بود، نه شیوه‌ی تبدیل توابع مسدودکننده به توابع غیرمسدودکننده. یک وضعیت رایج زمانی است که می‌خواهید از تابعی مسدودکننده در برنامه‌ی خود استفاده کنید،‌ اما تغییر کدهای درون تابع ممکن نیست.

این وضعیت معمولا زمان استفاده از کتابخانه‌های third-party رخ می‌دهد. یک مثال عالی کتابخانه‌ی requests است که از فراخوانی‌های مسدودکننده [^8] استفاده می‌کند. اگر نمی‌توانید کدی که فراخوانی می‌شود را تغییر دهید، روش دیگری وجود دارد. اینجا زمان مناسبی است که به شما نشان دهم چگونه یک اجراکننده می‌تواند برای همین کار مورد استفاده قرار بگیرد. این روش در مثال 23-2 نشان داده شده است.

مثال 23-2. روش غیرمسدودکننده با کمی کمک از دوستانم


``` python
@asynccontextmanager
async def web_page(url): #1
    loop = asyncio.get_event_loop()
    data = await loop.run_in_executor(
       None, download_webpage, url) #2
    yield data
    
    await loop.run_in_executor(None, update_stats, url) #3
async with web_page('google.com') as data:
    process(data)
```

<ol>
<li>
برای این مثال،‌ تصور کنید که نمی‌توانیم کد مربوط به دو تابع مسدودکننده را تغییر دهیم، ()download_webpage و ()update_stats؛ یعنی ما نمی‌توانیم این توابع را به توابع coroutine تبدیل کنیم. این بد است، زیرا بزرگ‌ترین گناه برنامه‌نویسی مبتنی بر رویداد شکستن این قانون است که هرگز و تحت هیچ شرایطی نباید از پردازش رویدادها توسط حلقه‌ی رویداد جلوگیری کنید. 
برای رفع این مشکل از یک اجراکننده برای اجرای بخش‌های مسدودکننده در یک thread جدا استفاده می‌کنیم. اجراکننده به عنوان یکی از attributeهای حلقه رویداد در دسترس ما قرار می‌گیرد. 
</li>
<li>
اجراکننده را فراخوانی می‌کنیم. امضای آن AbstractEventLoop.run_in_execu
tor(executor, func, *args) است. اگر می‌خواهید از اجراکننده‌ی پیش‌فرض استفاده کنید (که یک ThreadPoolExecutor است)، باید None را به عنوان مقدار برای آرگومان اجراکننده ارسال کنید [^9].
</li>
<li>
همانند فراخوانی <code>()download_webpage</code>، دیگر فراخوانی مسدودکننده که ()update_stats است را نیز در یک اجراکننده اجرا می‌کنیم. توجه داشته باشید که باید از کلیدواژه‌ی await استفاده کنید. اگر این مورد را فراموش کنید، اجرای generator ناهمزمان (یعنی همان async context manager) برای تمام شدن فراخوانی صبر نخواهد کرد. 
</li>
</ol>

احتمال استفاده از async context managerها در بسیاری از کدهای مبتنی بر asyncio زیاد است، به همین دلیل هم درک بالا از این موارد بسیار مهم است. می‌توانید برای مطالعه بیشتر درباره دکوراتور جدید asynccontextmanager@ به [داکیومنت‌ Python3.7](https://docs.python.org/3.7/library/contextlib.html#contextlib.asynccontextmanager) مراجعه کنید. 


### Async Iterators: async for

بخش بعدی نسخه‌ی sync حلقه‌ی for است. فهم این بخش در صورتی که بدانید حلقه‌ی تکرار معمولی با استفاده از متدهای ویژه پیاده‌سازی می‌شوند-درست مانند دیگر قابلیت‌های زبان-. این متد‌های ویژه توسط __ در نام‌هایشان مشخص می‌شوند. مثلا در مثال 24-3 نشان‌ می‌دهد که یک حلقه‌ی تکرار استاندارد (ناهمگام) چگونه با استفاده از متدهای ()__iter__ و ()__next__ پیاده‌سازی می‌شود. 

مثال 24-3. یک حلقه‌ی تکرار سنتی و ناهمگام


``` python
>>> class A:
...     def __iter__(self): #1
...         self.x = 0 #2
...         return self #3
...     def __next__(self): #4
...         if self.x > 2:
...             raise StopIteration #5
...         else:
...             self.x += 1
...             return self.x #6
>>> for i in A():
...     print(i)
1
2
3
```

<ol>
<li>
حلقه‌ی تکرار باید متد ویژه‌ی ()__iter__ را پیاده‌سازی کند. 
</li>
<li>
وضعیت را به وضعیتِ آغاز تغییر دهید. 
</li>
<li>
متد ویژه‌ی ()__iter__ باید یک iterable بازگرداند. یعنی شي‌ای که متد ویژه‌ی ()__next__ را پیاده‌سازی می‌کند. در این نمونه، همان instance بازگردانده می‌شود، زیرا A نیز خود متد ویژه‌ی ()__next__ را پیاده‌سازی می‌کند.
</li>
<li>
متد ()__next__ تعریف شده است. این متد برای هر مرحله در دنباله‌ی تکرار فراخوانی می‌شود تا زمانی که...
</li>
<li>
...StopIteration مطرح می‌شود.
</li>
<li>
مقادیر بازگشتی برای هر تکرار تولید می‌شوند.
</li>
</ol>

حال می‌پرسید: اگر متد ویژه‌ی `()__next__` را به عنوان یک تابع coroutine با async def تعریف کنیم چه اتفاقی می‌افتد؟ این کار به متد ما اجازه می‌دهد که برای برخی از عملیات‌های محدود به I/O از await استفاده کند-که این در واقع همان شیوه‌ای است که async کار می‌کند، به جز برخی جزئیات کوچک برای نامگذاری‌ها. اطلاعات PEP 492 نشان می‌دهند که برای استفاده از async بر روی یک async iterator، به موارد گوناگونی در خودِ async iterator نیاز خواهد بود:

<ol>
<li>
باید تابع <code dir='rtl'>()__aiter__</code> را پیاده‌سازی کنید. (البته نه با async def!)
</li>
<li>
تابع <code>()__aiter__</code> باید شئ‌ای را بازگرداند که تابع ناهمگام <code>()__anext__</code> را پیاده‌سازی کند. 
</li>
<li>
تابع <code>()__anext__</code> باید برای هر تکرار مقداری را بازگردانده و به هنگام پایان نیز <code>StopAsync Iteration</code> را بازگرداند.
</li>
</ol>

---

بیاید نگاهی گذار به نحوه عملکرد این مسئله بینداریم. تصور کنید که تعدادی key در یک دیتابیس [Redis](https://redis.io/) داریم،‌ و می‌خواهیم روی داده‌های آن‌ها حرکتی را تکرار کنیم؛ اما ما داده‌ها را تنها در زمان تقاضا واکشی می‌کنیم. یک حلقه‌ی تکرارشونده‌ی async برای این کار ممکن است مانند مثال 25-3 باشد.

مثال 25-3. حلقه‌ی async برای واکشی داده‌ها از redis.


```python
import asyncio
from aioredis import create_redis

async def main(): #1
    redis = await create_redis(('localhost', 6379)) #2
    keys = ['Americas', 'Africa', 'Europe', 'Asia'] #3

    async for value in OneAtATime(redis, keys): #4
        await do_something_with(value) #5

class OneAtATime: #6
    def __init__(self, redis, keys):
        self.redis = redis
        self.keys = keys
    def __aiter__(self): #7
        self.ikeys = iter(self.keys)
        return self
    async def __anext__(self): #8
        try:
            k = next(self.ikeys) #9
        except StopIteration: #10
            raise StopAsyncIteration
        value = await redis.get(k) #11
        return value

asyncio.run(main())
```

<ol>
<li>
تابع ()main: این تابع را با استفاده از ()asyncio.run در انتهای کد اجرا می‌کنیم. 
</li>
<li>
از رابط سطح بالای aioredis برای دریافت اتصال استفاده می‌کنیم. 
</li>
<li>
تصور کنید که هر یک از مقادیری که با این کلیدها در ارتباط هستند مقادیر بزرگی بوده و در یک instance از Redis ذخیره شده‌اند. 
</li>
<li>
از async for استفاده می‌کنیم: نکته این است که مکانیزم تکرار قادر است خود را در حالی که منتظر رسیدن داده‌ی بعدی است به حالت تعلیق درآورد. 
</li>
<li>
برای کامل‌تر شدن، تصور کنید که فعالیت‌های محدود به I/O نیز بر روی مقادیر واکشی‌شده انجام می‌دهیم-شاید یک تبدیلِ ساده داده-و سپس به مقصدی دیگر ارسال می‌شود.
</li>

---

<li>
مقداردهی اولیه این کلاس کاملا معمولی است: ما نمونه‌ی اتصال Redis و لیست کلیدها را برای تکرار ذخیره می‌کنیم.
</li>
<li>
همانطور که در مثال قبلی با ()__iter__ داشتیم، از ()__aiter__ برای تنظیم موارد مختلف برای iteration استفاده می‌کنیم. یک تکرارشونده‌ی معمولی برای کلیدها ایجاد می‌کنیم، self.ikeys، و self را بازمی‌گردانیم، زیرا OneAtATime نیز متد ()ــanext__  که coroutine است را پیاده‌سازی می‌کند. 
</li>
<li>
توجه داشته باشید که تابع ()__anext__ با async def تعریف شده است، در حالی که تابع ()__aiter__ تنها با def تعریف شده است.
</li>
<li>
زمانی که self.ikeys تمام می‌شود، StopIteration را مدیریت می‌کنیم و به سادگی آن را به StopAsyncIteration تبدیل می‌کنیم! به این صورت است که از داخل یک تکرارکننده‌ی async سیگنال توقف می‌دهیم.
</li>
<li>
در نهایت-تمام هدفِ ما از این مثال-می‌توانیم داده‌ها را از Redis مرتبط با این کلید دریافت کنیم. می‌توانیم داده را await کنیم، که به بدان معناست است که در حالی که منتظر I/O شبکه هستیم، باقی برنامه می‌تواند در حلقه‌ی رویداد اجرا شود. 
</li>
</ol>

امیدوارم این مثال شفاف باشد: async for توانایی حفظ راحتی یک حلقه‌ی for ساده را فراهم می‌کند، حتی زمان تکرار روی داده‌ها در جایی که خودِ تکرار در حال انجام I/O است. مزیت این است که شما می‌توانید مقادیر بسیار زیاد داده را با استفاده از تنها یک حلقه پردازش کنید، زیرا باید با هر بخش از داده در دسته‌های کوچک کار کنید. 

### کد ساده‌تر با Async Generators

<p dir='rtl'>
generatorهای ناهمگام در واقع توابع async def هستند که کلمات کلیدی yield را داخل خود دارند. استفاده از async generatorها می‌تواند به ساده‌تر شدن کدها بینجامد. 
</p>

با این وجود، اگر تجربه استفاده از generatorها را داشته باشید، مانند فریمورک Twisted، یا فریمورک Tornado، و یا حتی yield از asyncio در Python 3.4، ممکن است ایده‌ی آن‌ها گیج‌کننده باشد. بنابراین، قبل از ادامه، بهتر است خود را متقاعد کنید که:

<ul>
<li>
coroutineها و generatorها مفاهیم کاملا مجزایی هستند.
</li>
</ul>
<ul>
<li>
generatorهای async مانند generatorهای معمولی عمل می‌کنند.
</li>
</ul>
<ul>
<li>
برای حلقه‌های تکرارشونده، به جای استفاده از for برای generatorهای معمولی، از async for برای generatorهای async استفاده کنید
</li>
</ul>

---

مثالی که در بخش قبل برای نشان دادن تکرارشونده‌ی async جهت ارتباط با Redis داشتیم، بسیار آسان‌تر خواهد بود اگر آن را به یک async generator تبدیل کنیم. این کار در مثال 26-3 نشان داده شده است.

مثال 26-3. استفاده از async generator کار را آسان‌تر می‌کند.

``` python
import asyncio
from aioredis import create_redis

async def main(): #1
    redis = await create_redis(('localhost', 6379))
    keys = ['Americas', 'Africa', 'Europe', 'Asia']

    async for value in one_at_a_time(redis, keys): #2
        await do_something_with(value)

async def one_at_a_time(redis, keys): #3
    for k in keys: 
        value = await redis.get(k) #4
        yield value #5

asyncio.run(main())
```

<ol>
<li>
تابع ()main کاملا مشابه نمونه‌ای است که در مثال 25-3 داشتیم.
</li>
<li>
البته تقریبا مشابه: من نام آن را از الگوی CamelCase به <code>snake_case</code> تغییر دادم. 
</li>
<li>
تابع ما اکنون با async def تعریف شده است، که آن را به یک تابع coroutine تبدیل می‌کند. و از آنجایی که این تابع دارای کلیدواژه‌ی yield نیز هست، ما آن را یک تابع generator ناهمگام می‌نامیم. 
</li>
<li>
ما نیاز به انجام کارهای پیچیده‌ با self.ikeys مانند مثال قبل نداریم: در اینجا تنها کافیست به طور مستقیم بر روی کلیدها حلقه بزنیم و مقدار را به دست آوریم...
</li>
<li>
...و سپس با استفاده از yield آن را به فراخواننده تابع می‌دهیم، دقیقا مانند generatorهای معمولی.
</li>
</ol>

اگر این مبحث برایتان جدید باشد ممکن است پیچیده به نظر رسد، اما من از شما می‌خواهم که با چند مثال تمرینی کمی با آن بازی کنید. با این کار این مبحث به سرعت برایتان طبیعی خواهد شد. generatorهای async احتمالا در برنامه‌های مبتنی بر asyncio محبوب خواهند شد، زیرا می‌توانند تمام مزایای generatorهای معمولی را فراهم کرده و کد را نیز کوتاه‌تر و آسان‌تر کنند. 

---

### Async Comprehensions

حال که چگونگیِ پشتیبانیِ پایتون از حلقه‌های تکرار ناهمگام را دیدیم، سوال بعدی این است که آیا این روش برای list comprehensionها نیز کار می‌کند؟ و جواب به این سوال مثبت است. این پشتیبانی در [PEP 530](https://peps.python.org/pep-0530/) معرفی شد. پیشنهاد می‌کنم که خودتان نگاهی به این PEP بیندازید، چرا که کوتاه و قابل خواندن است. مثال 27-3 نشان می‌دهد که async comprehensionها چگونه پیاده‌سازی می‌شوند.

مثال 27-3. list, dict, و set comprehensionهای ناهمگام

``` python
>>> import asyncio
>>>
>>> async def doubler(n):
...     for i in range(n):
...         yield i, i * 2 #1
...         await asyncio.sleep(0.1) #2
...
>>> async def main():
...     result = [x async for x in doubler(3)] #3
...     print(result)
...     result = {x: y async for x, y in doubler(3)} #4
...     print(result)
...     result = {x async for x in doubler(3)} #5
...     print(result)
...
>>> asyncio.run(main())
[(0, 0), (1, 2), (2, 4)]
{0: 0, 1: 2, 2: 4}
{(2, 4), (1, 2), (0, 0)}
```

<ol>
<li>
تابع ()doubler یک generator ناهمگام بسیار ساده است: با توجه به مقدار بالایی، بر روی محدوده‌ی ساده‌ای تکرار شده و یک tuple از مقدار به همراه دو برابر آن را yield می‌کند. 
</li>
<li>
کمی بخوابید، فقط برای تاکید بر اینکه این تابع واقعا یک تابع async است.
</li>
<li>
به عنوان یک list comprehension ناهمگام: به استفاده از async for به جای for معمولی توجه داشته باشید. این تفاوت دقیقا همانند موردی است که در مثال‌های ["Async Iteraors: async for" در صفحه 50](#async-iterators-async-for) نشان داده شد. 
</li>
<li>
یک dict comprehension ناهمگام؛ تمام ترفندهای معمول کار می‌کنند، مثل باز کردن tuple به x و y، تا بدین ترتیب بتوانیم از سینتکس dict comprehension استفاده کنیم.
</li>
<li>
set comprehencion ناهمگام دقیقا همانطور که انتظار دارید کار می‌کند. 
</li>
</ol>

---

همچنین می‌توانید همانطور که در PEP 530 بیان شده است، داخل comprehensionها از await استفاده کنید. این قابلیت نباید قافلگیرکننده باشد؛ await coro یک عبارت معمولی است و می‌تواند در بسیاری از مکان‌هایی که انتظارش را دارید مورد استفاده قرار گیرد. 

این async for است که یک comprehension را به یک async comprehension تبدیل می‌کند، نه حضور await. تمام چیزی که برای قانونی بودن await درون یک comprehension لام است،‌ استفاده از آن در داخل یک تابع coroutine است، یعنی تابعی که با async def تعریف شده باشد. استفاده از await و async داخل یک list comprehension یکسان در واقع ترکیب دو مفهوم مجزا است،‌اما ما در هر صورت این کار را در مثال 28-3 انجام می‌دهیم تا مطمئن شویم که شما با سینتکس async آشنایی دارید. 

مثال 28-3. کنار هم گذاشتن همه چیز.

``` python
>>> import asyncio
>>>
>>> async def f(x): #1
...     await asyncio.sleep(0.1)
...     return x + 100
...
>>> async def factory(n): #2
...     for x in range(n):
...         await asyncio.sleep(0.1)
...         yield f, x #3
...
>>> async def main():
...     results = [await f(x) async for f, x in factory(3)] #4
...     print('results = ', results)
...
>>> asyncio.run(main())
results = [100, 101, 102]
```

<ol>
<li>
یک تابع coroutine ساده: کمی بخوابید، سپس پارامتر به اضافه 100 را بازگردانید.
</li>
<li>
این یک generator ناهمگام است،‌ که کمی پایین‌تر در داخل یک list comprehension ناهمگام با استفاده از async for  برای هدایت حلقه تکرار فراخوانی می‌شود. 
</li>
<li>
generator ناهمگام یک تاپل شامل f و متغیر تکرارشونده‌ی x را yield می‌کند. f یک تابع coroutine است، اما هنوز coroutine نیست.
</li>
<li>
بالاخره، comprehension ناهمگام. این مثال برای نشان دادن یک comprehension که شامل async for و await است ساخته شده است. بیاید اتفاقی که داخل comprehension می‌افتد را بررسی کنیم. اول، فراخوانی (3)factory یک generator ناهمگام را بازمی‌گرداند که توسط حلقه‌ی تکرارشونده تولید شده است. به خاطر آنکه این مقدار بازگشتی یک async generator است نمی‌توان از for استفاده کرد؛ بلکه باید از async for استفاده کنیم. 
</li>
</ol>

---

مقادیری که از generator ناهمگام تولید می‌شوند یک تاپل شامل تابع coroutine به نام f و یک عدد است. فراخوانی تابع ()f یک coroutine تولید می‌کند، که باید با استفاده از await ارزیابی شود. 

توجه داشته باشید که داخل comprehension استفاده از await هیچ ارتباطی با استفاده از async for ندارد: این دو کارهای کاملا متفاوتی انجام داده و بر روی اشیاء متفاوتی تاثیر می‌گذارند. 

### راه‌اندازی و خاموشی به شکل صحیح

بسیاری از برنامه‌های مبتنی بر async برنامه‌های طولانی مدت و مبتنی بر شبکه خواهند بود. این دامنه پیچیدگی شگفت‌انگیزی در برخورد با نحوه راه‌اندازی و خاموش شدن به شکل صحیح دارد. 

از بین راه‌اندازی و خاموشی، راه‌اندازی آسان‌تر است. روش استاندارد برای راه‌اندازی یک برنامه‌ی async، داشتنِ یک تابع coroutine به نام ()main و فراخوانی آن با ()asyncio.run است، همانطور که در [مثال 2-3](./examples/3-2.py) در ابتدای این فصل نشان داده شده است. 

به طور کلی،‌ به دلیل مسئله‌ی سرور که پیش‌تر توضیح داده شد، راه‌اندازی نسبتا ساده خواهد بود. شما می‌توانید در [داکیومنت](https://docs.python.org/3/library/asyncio-stream.html#tcp-echo-server-using-streams) بیش‌تر درباره این مسئله بخوانید. همچنین در یکی از مثال‌های پیش رو به راه‌اندازی سرور نگاهی مختصر خواهیم انداخت. 

خاموشی بسیار پیچیده‌تر است. برای خاموشی، پیش‌تر روندی که داخل ()asyncio.run  اتفاق می‌افتد را بررسی کردیم. زمانی که تابع ()async def main وجود دارد، عملیات زیر اجرا می‌شوند:

<ol>
<li>
تمام آبجکت‌های task که هنوز در انتظار هستند جمع‌آوری می‌‌شوند. 
</li>
<li>
taskهای جمع‌اوری شده کنسل می‌شوند (این کار موجب بروز خطای CancelledError  در هر یک از coroutine‌های در حال اجرا می‌شود. ممکن است بخواهید این خطا را با استفاده از try/except درون بدنه‌ی تابع coroutine کنترل کنید.)
</li>
<li>
تمام این taskها را درون یک group task جمع کنید.
</li>
<li>
از ()run_until_complete بر روی group task استفاده کنید تا بتوانید تا زمانی که تمام می‌شوند برایشان صبر کنید. یعنی اجازه دهید خطای CancelledError مطرح شده و با آن برخورد شود. 
</li>
</ol>

تابع ()asyncio.run این عملیات‌ را برای شما انجام می‌دهد. اما با وجود چنین کمکی، در ساخت اولین‌ برنامه‌های مهم asyncio در تلاش برای رفع خطاهایی مانند“Task was destroyed but it is pending!”  در زمان خاموشی مواجه خواهید بود. این اتفاق به این دلیل می‌افتد که برنامه‌ شما آمادگی یک یا چند مورد از مراحل گفته شده را نداشته است. مثال 29-3 مثالی از یک قطعه کد است که این خطای آزاردهنده را تولید می‌کند. 

مثال 29-3. از بین‌برنده‌ی taskهای در حال انتظار

``` python
# taskwarning.py
import asyncio
async def f(delay):
    await asyncio.sleep(delay)

loop = asyncio.get_event_loop()
t1 = loop.create_task(f(1))
t2 = loop.create_task(f(2))
loop.run_until_complete(t1)
loop.close()
```

<ol>
<li>
task شماره 1 برای 1 ثانیه اجرا خواهد شد
</li>
<li>
task شماره 2 برای 2 ثانیه اجرا خواهد شد
</li>
<li>
تنها تا زمانی ادامه بده که task شماره 1 کامل شود.
</li>
</ol>

اجرای این برنامه خروجی زیر را تولید خواهد کرد:

``` shell
$ python taskwarning.py
Task was destroyed but it is pending!
task: <Task pending coro=<f() done, defined at [...snip...]>
```

این خطا به شما می‌گوید که برخی از taskها زمانی که حلقه بسته شد کامل نشده بودند. ما باید از این امر اجتناب کنیم، و برای همین است که عملیات خاموشی این است که تمام taskهای ناتمام را جمع‌آوری کنید، لغو کنید، و همچنین بگذارید همه آن‌ها پیش از بسته شدن حلقه تمام شوند. تابع ()asyncio.run تمامی این مراحل را برای شما انجام می‌دهد، اما مهم است که فرایند را با جزئیات بدانید تا بتوانید شرایط پیچیده‌تر را کنترل کنید. 

بیایید به یک مثال جزئی‌تر که تمام این مراحل را نشان می‌دهد نگاهی بیندازیم. مثال 30-3 یک موردپژوهی کوچک با سرور echo مبتنی برا Telnet است. 

مثال 30-3. چرخه عمر برنامه asyncio (بر اساس سرور اکو TCP در داکیومنت پایتون)

``` python
# telnetdemo.py
import asyncio
from asyncio import StreamReader, StreamWriter

async def echo(reader: StreamReader, writer: StreamWriter): #1
    print('New connection.')
    try:
        while data := await reader.readline(): #2
            writer.write(data.upper()) #3
            await writer.drain()
        print('Leaving Connection.')
    except asyncio.CancelledError: #4
        print('Connection dropped!')
async def main(host='127.0.0.1', port=8888):
    server = await asyncio.start_server(echo, host, port) #5
    async with server:
        await server.serve_forever()

try:
    asyncio.run(main())
except KeyboardInterrupt:
    print('Bye!')
```

<ol>
<li>
تابع ()echo که یک coroutine است توسط سرور برای ساخت یک coroutine برای هر اتصال ساخته خواهد شد. این تابع از streams API برای عملیات شبکه با asyncio استفاده می‌کند. 
</li>
<li>
برای زنده نگه داشتن اتصال، یک حلقه‌ی بی‌نهایت جهت صبر کردن برای پیام‌ها خواهیم داشت. 
</li>
<li>
داده‌ها را به ارسال‌کننده بازمی‌گردانیم، البته با حروف بزرگ.
</li>
<li>
اگر این task لغو شد،‌ یک پیام چاپ خواهیم کرد. 
</li>
<li>
این برنامه برای راه‌اندازی سرور TCP مستقیما از داکیومنت Python 3.8 برداشته شده است. 
</li>
</ol>

پس از راه‌اندازی سرور echo، می‌توانید به آن متصل شده و با آن تعامل داشته باشید. 

``` shell
$ telnet 127.0.0.1 8888
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
hi!
HI!
stop shouting
STOP SHOUTING
^]
telnet> q/
Connection closed.
```

خروجی سرور برای آن session به این شکل است (سرور تا زمانی که Ctrl-C را فشار دهیم به کار خود ادامه می‌دهد):

``` python
$ python telnetdemo.py
New connection.
Leaving Connection.
^CBye!
```
در Telnet session که نشان داده شد،  client  (یعنی Telnet) اتصال را پیش از آنکه سرور متوقف شود لغو کرد، اما بیاید ببینیم اگر سرور را در حالی که یک اتصال همچنان فعال است ببندیم چه می‌شود. خروجی زیر را از فرایند سرور مشاهده خواهیم کرد:

``` shell
$ python telnetdemo.py
New connection.
^CConnection dropped!
Bye!
```

---

در اینجا می‌توانید مشاهده کنید که کنترل‌کننده‌ی خطا برای CancelledError فعال شد. حال تصور کنید که این برنامه یک برنامه‌ی واقعی است، و می‌خواهیم تمام رویدادهای مربوط به اتصالات قطع شده را به یک سرویس مانیتورینگ ارسال کنیم. این نمونه کد می‌تواند مانند مثال 31-3 تغییر کند.

مثال 31-3. ساخت task در کنترل‌کننده‌ی خطا.

``` python
# telnetdemo.py
import asyncio
from asyncio import StreamReader, StreamWriter

async def send_event(msg: str): #1
    await asyncio.sleep(1)

async def echo(reader: StreamReader, writer: StreamWriter):
     print('New connection.')
    try:
        while (data := await reader.readline()):
            writer.write(data.upper())
            await writer.drain()
        print('Leaving Connection.')
    except asyncio.CancelledError:
        msg = 'Connection dropped!'
        print(msg)
        asyncio.create_task(send_event(msg)) #2

async def main(host='127.0.0.1', port=8888):
    server = await asyncio.start_server(echo, host, port)
    async with server:
        await server.serve_forever()

try:
    asyncio.run(main())
except KeyboardInterrupt:
    print('Bye!')
```

<ol>
<li>
فکر کنید که این coroutine واقعا با یک سرور خارجی ارتباط برقرار می‌کند تا اعلان‌های مربوط به رویدادها را ثبت کند. 
</li>
<li>
از آنجایی که اعلام‌کننده‌ی رویداد شامل دسترسی شبکه است، رایج است که اینگونه فراخوانی‌ها در یک async task مجزا انجام شوند؛ به همین دلیل هم در اینجا از تابع ()create_task استفاده می‌کنیم. 
</li>
</ol>

با این وجود این برنامه یک مشکل دارد. این مشکل زمانی مشخص می‌شود که یک مثال را دوباره اجرا کرده و سرور را در زمانی که اتصال همچنان فعال است با Ctrl-C متوقف کنیم:

``` shell
$ python telnetdemo.py
New connection.
^CConnection dropped!
Bye!
Task was destroyed but it is pending!
task: <Task pending name='Task-6' coro=<send_event() done, ...>
```

برای آنکه درک کنیم چرا این اتفاق می‌افتد، باید به روند رویدادهای cleanup که ()asyncio.run در زمان خاموشی انجام می‌دهد بازگردیم. مهم‌ترین بخش این است که زمانی که Ctrl-C را فشار می‌دهیم، تمام taskهایی که فعال هستند جمع‌آوری شده و لغو می‌شوند. در این مرحله، تنها همان taskها await می‌شوند، و ()asyncio.run بلافاصله پس از آن برمی‌گردد. مشکل کد اصلاح‌شده‌ی ما این است یک task جدید در کنترل‌کننده‌ی خطا که داخل تسک "echo" است ساختیم. این task جدید زمانی ساخته شد که ()asyncio.run تمام تسک‌های موجود را جمع‌آوری و لغو کرده است. 

به همین دلیل است که باید از چگونه کار کردن ()asyncio.run اطلاع داشته باشید. 

<img style="float: left;width:120px;height:120px" src="./images/2.png">

به عنوان یک قانون کلی، سعی کنید از ساخت taskهای جدید در کنترل‌کننده‌ی خطای CancelledError اجتناب کنید.  اگر ناچار به انجام این کار هستید،‌ مطمئن شوید که task جدید  یا future را در محدوده‌ی همان تابع await کنید.

و در آخر: اگر از یک کتابخانه یا فریمورک استفاده می‌کنید، مطمئن شوید که از داکیومنت آن برای راه‌اندازی و خاموشی صحیح استفاده می‌کنید. فریمورک‌های third-party معمولا توابع خود برای راه‌‌اندازی و خاموشی و همچنین event hookهایی برای شخصی‌سازی ارائه می‌دهند. می‌توانید مثالی از این hookها را با فریمورک Sanic در [“موردپژوهی: Cache Invalidation” در صفحه 115](https://github.com/ftg-iran/aip-persian/blob/main/04-20%20Asyncio%20Libraries%20You%20Aren%E2%80%99t%20Using/README.md#case-study-cache-invalidation) مشاهده کنید. 

<h3 dir='rtl'> return_exceptions=True در ()gather چیست؟ </h3>

ممکن است در فراخوانی تابع ()gather در مثال‌های 3-3 و 1-3 در توالی روند خاموشی متوجه آرگومان کلمه کلیدی return_exceptions=True شده باشید. من در آن زمان چیزی درباره این مورد نگفتم. تابع ()asyncio.run نیز از ()gather و return_exceptions=True به صورت داخلی استفاده می‌کند. زمان آن رسیده است که درباره این مورد بیش‌تر صحبت کنیم. 

متاسفانه پیش‌فرض به صورت (return_exceptions=False, ...)gather است. این پیش‌فرض برای بسیاری از شرایط از جمله فرایند خاموشی مشکل‌ساز است، و به همین دلیل هم ()asyncio.run این پارامتر را True می‌کند. توضیح مستقیم این مورد کمی پیچیده است؛ به جای این کار، بیاید به دنباله‌ای از مشاهدات نگاهی بیندازیم که فهم این مسئله را آسان‌تر می‌کنند:

<ol>
<li>
تابع ()run_until_complete بر روی یک future عمل می‌کند؛ در زمان خاموشی، این future است که توسط ()gather بازگردانده می‌شود. 
</li>
<li>
اگر این future موجب بروز خطایی شود، خطا از ()run_until_conplete نیز خارج می‌شود، که به معنای توقف حلقه است. 
</li>
<li>
اگر از ()run_until_conplete بر روی گروهی از futureها استفاده می‌شود، هر خطایی که در هر یک از subtaskها رخ می‌دهد، اگر در همان subtask کنترل نشود، در future گروهی نیز رخ خواهد داد. توجه داشته باشید که خطاها شامل CancelledError نیز می‌شوند.
</li>
<li>
اگر تنها برخی از taskها خطای CancelledError را کنترل کرده و برخی دیگر این کار را نکنند، taskهایی که این کار را انجام نمی‌دهند موجب توقف حلقه می‌شوند. این بدان معناست که حلقه پیش از آنکه تمام taskها تمام شوند متوقف خواهد شد. 
</li>
<li>
برای خاموشی، به هیچ وجه چنین رفتاری را نمی‌خواهیم. ما می خواهیم ()run_until_complete تنها زمانی تمام شود که تمام taskها در گروه بدون در نظر گرفتن خطاهایی که در آن‌ها رخ می‌دهد تمام شده باشند. 
</li>
<li>
بدین ترتیب از (return_exceptions=True, *)gather استفاده می‌کنیم: این تنظیمات موجب می‌شود future گروهی با خطاها مانند مقادیر بازگشتی از subtaskها برخورد کند، تا خطاها با ()run_until_complete تداخل نداشته باشند. 
</li>
</ol>

حال باید به خوبی متوجه رابطه‌ی return_exceptions=True و ()run_until_complete شده باشید. یکی از عواقب استفاده از این روش برای گرفتن خطاها این است که ممکن است برخی از این خطاها مورد توجه شما قرار نگیرند، زیرا در داخل task گروهی کنترل می‌شوند. اگر این مسئله موجب نگرانی شما می‌شود، می‌توانید لیست خروجی‌ها از ()run_until_complete را گرفته و آن را برای هر زیرکلاسی از Exception بررسی کنید، سپس می‌توانید متناسب با شرایط خود log messageهایی نیز داشته باشید. مثال 32-3 این رویکرد را نشان می‌دهد.

مثال 32-3. تمام taskها تمام می‌شوند.

``` python
# alltaskscomplete.py
import asyncio

async def f(delay):
    await asyncio.sleep(1 / delay) #1
    return delay

loop = asyncio.get_event_loop()
for i in range(10):
    loop.create_task(f(i))
pending = asyncio.all_tasks()
group = asyncio.gather(*pending, return_exceptions=True)
results = loop.run_until_complete(group)
print(f'Results: {results}')
loop.close()
```

<ol>
<li>
اگر کسی 0 را به عنوان ورودی قرار دهد افتضاح می‌شود...
</li>
</ol>

خروجی بدین صورت است:

``` shell
$ python alltaskscomplete.py
Results: [6, 9, 3, 7, ...
 ZeroDivisionError('division by zero',), 4, ...
 8, 1, 5, 2]
```

بدون استفاده از return_exceptions=True، خطای ZeroDivisionError  از درون ()run_until_complete رخ داده و حلقه را متوقف می‌کند، و بدین ترتیب از تمام شدن باقی taskها جلوگیری می شود. 

در بخش بعدی، درباره کنترل signalها (فرای KeyboardInterrupt) صحبت خواهیم کرد، اما پیش از آن که به آنجا برسیم، مهم است که به خاطر داشته باشید که خاموشی به روش صحیح یکی از مشکل‌ترین جنبه‌های برنامه‌نویسی شبکه است، و برای asyncioنیز همینطور است. اطلاعات این بخش فقط یک شروع است. بهتر است برای خاموشی به روش صحیح از تست‌‌های خاص در مجموعه‌های تست خودکار خود استفاده کنید. برنامه‌های مختلف معمولا نیاز به استراتژی‌های مختلف دارند. 

<img style="float: left;width:120px;height:120px" src="./images/2.png">

من یک پکیج کوچک در (PyPI) Python package index به نام [aiorun](https://pypi.org/project/aiorun/) منتشر کرده‌ام. این پکیج در درجه‌ی اول برای آزمایشات و آموزش‌ خودم در برخورد با خاموشی asyncio است که شامل ایده‌های بسیاری از این بخش می‌شود. ممکن است برای شما نیز مفید باشد که با کد بازی کرده و ایده‌های خود در زمینه‌ی سناریوهای خاموشی صحیح در asyncio را بررسی کنید. 


### سیگنا‌ل‌ها

مثال‌های قبلی نشان دادند که حلقه‌ی رویداد چگونه با KeyboardInterrupt متوقف می‌شود؛ یعنی فشردن Ctrl-C. در داخل ()asyncio.run خطای KeyboardInterrupt به طور موثر یک فراخوانی ()loop.run_until_complete را از حالت انسداد خارج کرده و امکان رخداد باقی فرایند خاموشی را فراهم می‌کند. 

خطای KeyboardInterrupt به سیگنال SIGINT پاسخ می‌دهد. در سرویس‌های شبکه، رایج‌ترین سیگنال برای پایان فرایندها سیگنال SIGTERM است که همان سیگنال پیش‌فرض در زمان اجرای دستور kill در Unix shell است.

<img style="float: left;width:120px;height:120px" src="./images/1.png">

دستور kill در سیستم‌های Unix به شکل فریبنده‌ای نامگذاری شده است. تمام کاری که این دستور انجام می‌دهد ارسال سیگنال به یک فرایند است. دستور kill <PID> بدون هیچ آرگومانی یک سیگنال TERM ارسال می‌کند: فرایند شما می‌تواند سیگنال را دریافت کرده و به شکل صحیح خاموش شود، و یا می‌تواند آن را نادیده بگیرد! البته نادیده گرفته شدن سیگنال ایده بدی است، زیرا اگر فرایند شما متوقف نشود، قدم بعدی اجرا شدن kill -s KILL <PID> است، که سیگنال KILL را ارسال می‌کند. این سیگنال شما را خاموش می‌کند و برنامه‌تان نمی‌تواند هیچ کاری درباره آن انجام دهد. دریافت سیگنال TERM (یا INT) فرصت شما برای خاموش شدن به شکلی کنترل شده است. 

---

کتابخانه‌ی asyncio دارای پشتیبانی داخلی برای کنترل سیگنال‌های فرایند است، اما پیچیدگی کنترل سیگنال به طور کلی بسیار بالا است (که به طور خاص برای asyncio نیست). ما نمی‌توانیم همه چیز را در اینجا پوشش دهیم،‌ اما می‌توانیم به برخی موارد اساسی‌تر نگاهی بیندازیم. مثال 13-3 خروجی زیر را تولید می‌کند:

``` shell
$ python shell_signal01.py
<Your app is running>
<Your app is running>
<Your app is running>
<Your app is running>
^CGot signal: SIGINT, shutting down.
```

همانطور که در آخرین خط نشان داده شده است، من Ctrl-C را برای متوقف شدن برنامه فشردم. مثال 33-3 به عمد از استفاده از ()asyncio.run دوری کرده است، زیرا می‌خواهم درباره تله‌هایی که ممکن است در کنترل دو مورد از رایج‌ترین سیگنال‌ها، یعنی SIGTERM و SIGINT با آن‌ها برخورد کنید به شما اخطار دهم. پس از آنکه درباره این موارد صحبت کردیم، یک مثال نهایی از کنترل سیگنال با استفاده از تابع ()asyncio.run به شما نشان‌ خواهم داد. 

مثال 33-3. استفاده از KeyboardInterrupt به عنوان کنترل‌کننده SIGINT.

``` python
# shell_signal01.py
import asyncio

async def main(): #1
    while True:
        print('<Your app is running>')
        await asyncio.sleep(1)

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    task = loop.create_task(main()) #2
    try:
        loop.run_until_complete(task)
    except KeyboardInterrupt: #3
        print('Got signal: SIGINT, shutting down.')
    tasks = asyncio.all_tasks(loop=loop)
    for t in tasks:
        t.cancel()
    group = asyncio.gather(*tasks, return_exceptions=True)
    loop.run_until_complete(group)
    loop.close()
```

<ol>
<li>
این بخش اصلی از برنامه ما است. برای آنکه همه چیز را ساده نگه داریم، در یک حلقه‌ی بی‌نهایت می‌خوابیم. 
</li>
<li>
این روند راه‌اندازی و خاموشی از قسمت قبل برایتان آشنا خواهد بود. ما ()main را برنامه‌ریزی می‌کنیم، ()run_forever را فراخوانی می‌کنیم،‌و برای چیزی که حلقه را متوقف کند صبر می‌کنیم. 
</li>
<li>
در این مورد،‌ تنها Ctrl-C حلقه را متوقف خواهد کرد. سپس KeyboardInterrupt را کنترل می‌کنیم و تمام بخش‌های مربوط به پاکسازی که در بخش قبلی به آن اشاره کردیم را انجام می‌دهیم. 
</li>
</ol>

تا اینجا همه چیز ساده و واضح است. حال می‌خواهم کمی همه چیز را پیچیده کنم. تصور کنید:

<ul>
<li>
یکی از همکارانتان از شما می‌خواهد علاوه بر سیگنال  SIGINT،‌ سیگنال SIGTERM را نیز به عنوان یک سیگنال خاموشی کنترل کنید. 
</li>
</ul>
<ul>
<li>
در برنامه‌ی واقعیتان،‌ لازم است که پاکسازی را درون تابع ()main که coroutine است انجام دهید؛ باید خطای CancelledError را کنترل کنید، و کد پاکسازی درون کنترل‌کننده‌ی خطا چندین ثانیه به طول می‌انجامد تا تمام شود. (تصور کنید که لازم است با همتایان شبکه ارتباط برقرار کرده و دسته‌ای از اتصالات سوکت را ببندید).
</li>
</ul>
<ul>
<li>
اگر چندین بار سیگنال‌هایی برای شما ارسال شود، برنامه‌تان نباید کارهای عجیب و غریب انجام دهد (مثلا اجرای مجدد هر یک از مراحل خاموشی)؛ پس از آنکه اولین سیگنال خاموشی را دریافت می‌کنید، باید هر یک از سیگنال‌های جدید را تا زمان خروج نادیده بگیرید. 
</li>
</ul>


کتابخانه asyncio در API خود دارای ساختار مناسبی برای کنترل تمام این شرایط است. مثال 34-3 کد ساده مربوط به مثال قبلی را تغییر می‌دهد تا از این قابلیت‌های جدید استفاده شود. 

مثال 34-3. کنترل سیگنال‌های SIGINT و SIGTERM، و توقف حلقه تنها برای یک بار. 

``` python
# shell_signal02.py
import asyncio
from signal import SIGINT, SIGTERM #1

async def main():
    try:
        while True:
            print('<Your app is running>')
            await asyncio.sleep(1)
    except asyncio.CancelledError: #2
        for i in range(3):
            print('<Your app is shutting down...>')
            await asyncio.sleep(1)

def handler(sig): #3
    loop.stop() #4
    print(f'Got signal: {sig!s}, shutting down.')
    loop.remove_signal_handler(SIGTERM) #5
    loop.add_signal_handler(SIGINT, lambda: None) #6

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    for sig in (SIGTERM, SIGINT): #7
        loop.add_signal_handler(sig, handler, sig)
        loop.create_task(main())
        loop.run_forever() #8
        tasks = asyncio.all_tasks(loop=loop)
    for t in tasks:
        t.cancel()
 group = asyncio.gather(*tasks, return_exceptions=True)
 loop.run_until_complete(group)
 loop.close()
```

<ol>
<li>
از ماژول کتابخانه استاندارد signal مقادیر سیگنال را import کنید. 
</li>
<li>
این بار تابع ()main که coroutine است به طور داخلی کمی از پاکسازی را انجام می‌دهد. زمانی که سیگنال لغو دریافت می‌شود (که با لغو شدن هر یک از taskها آغاز می‌شود) یک بازه‌ی 3 ثانیه‌ای وجود خواهد داشت که ()main در حین مرحله‌ی ()run_until_complete از فرایند خاموشی به اجرا ادامه خواهد داد. در این بازه پیام  “...Your app is
shutting down” چاپ خواهد شد. 
</li>
<li>
این یک کنترل‌کننده‌ی callback برای زمانی است که سیگنالی دریافت می‌کنیم. این بخش توسط فراخوانی تابع ()add_signal_handler در حلقه تنظیم می‌شود که کمی پایین‌تر به آن می‌رسیم. 
</li>
<li>
هدف اصلی کنترل‌کننده متوقف کردن حلقه است: این خط ()loop.run_forever را رفع انسداد کرده و اجازه‌ی جمع‌اوری و لغو کردن تسک‌های در حال انتظار و اجرای ()run_complete برای خاموشی را می دهد.
</li>
<li>
از آنجایی که الان در مود خاموشی هستیم، نمی‌خواهیم هیچ سیگنال SIGINT یا SIGTERM این کنترل‌کننده را مجددا فعال کند: در اینصورت ()loop.stop در زمان اجرای ()run_until_complete فراخوانی می‌شود، که می‌تواند با فرایند خاموشی تداخل پیدا کند. به همین دلیل کنترل‌کننده‌ی سیگنال برای SIGTERM را از حلقه حذف می‌کنیم. 
</li>
<li>
نمی‌توانیم به سادگی کنترل‌کننده برای سیگنال SIGINT را حذف کنیم، زیرا اگر این کار را انجام دهیم،‌ مجددا KeyboardInterrupt به کنترل‌کننده برای SIGINT تبدیل خواهد شد، همانطور که پیش از اضافه کردن کنترل‌کننده‌های خودمان داشتیم. به جای این کار، یک تابع lambda خالی را به عنوان کنترل‌کننده قرار می‌دهیم. این بدان معناست که KeyboardInterrupt از روند کار ما دور مانده و SIGINT و Ctrl-C هیچ تاثیری ندارند. [10^].
</li>
<li>
در اینجا کنترل‌کننده‌های سیگنال به حلقه متصل می‌شوند. توجه داشته باشید که همانطور که پیش‌تر گفتیم،‌ تنظیم کردن یک کنترل‌کننده یا SIGINT بدان معناست که KeyboardInterrupt مجددا در زمان SIGINT رخ نمی‌دهد. رخ دادن KeyboardInterrupt کنترل‌کننده‌ی پیش‌فرض برای SIGINT بوده و در پایتون تنظیم شده است، تا زمانی که شما خودتان کاری کنید که کنترل‌کننده تغییر کند، همین کاری که ما در اینجا در حال انجام آن هستیم. 
</li>
<li>
طبق معمول، اجرا در ()run_forever تا زمانی که چیزی حلقه را متوقف کند مسدود می‌شود. در این مورد،‌ اگر هر یک از سیگنال‌های SIGINT یا SIGTERM به فرایند ما ارسال شود، حلقه در داخل ()handler متوقف می‌شود. باقی کد مانند قبل است. 
</li>
</ol>

خروجی بدین صورت است:

``` python
$ python shell_signal02.py
<Your app is running>
<Your app is running>
<Your app is running>
<Your app is running>
<Your app is running>
^CGot signal: Signals.SIGINT, shutting down.
<Your app is shutting down...>
^C<Your app is shutting down...> #1
^C<Your app is shutting down...>
```

<ol>
<li>
در زمان خاموشی چندین بار Ctrl-C را فشار دادم،‌ اما همانطور که انتظار می‌رفت، تا زمانی که تابع ()main کامل شد هیچ اتفاقی نیفتاد. 
</li>
</ol>

در این مثال‌ها، من چرخه زندگی حلقه رویداد را به روش سخت کنترل کرده‌ام، اما انجام این کارها برای توضیح اجزای پروسه خاموشی ضروری بود. در عمل، استفاده از تابع  ()asyncio.run که راحت‌تر است را ترجیح می دهیم.

مثال 35-3 ویژگی‌های طراحی کنترل‌کننده سیگنال قبلی را حفظ می‌کند، اما همچنین از راحتی ()asyncio.run نیز استفاده می‌کند.

مثال 35-3. کنترل سیگنال در زمان استفاده از ()asyncio.run 


``` python
# shell_signal02b.py
import asyncio
from signal import SIGINT, SIGTERM

async def main():
    loop = asyncio.get_running_loop()
    for sig in (SIGTERM, SIGINT):
        loop.add_signal_handler(sig, handler, sig) #1
    try:
        while True:
            print('<Your app is running>')
            await asyncio.sleep(1)
    except asyncio.CancelledError:
        for i in range(3):
            print('<Your app is shutting down...>')
            await asyncio.sleep(1)

def handler(sig):
    loop = asyncio.get_running_loop()
    for task in asyncio.all_tasks(loop=loop): #2
        task.cancel()
    print(f'Got signal: {sig!s}, shutting down.')
    loop.remove_signal_handler(SIGTERM)
    loop.add_signal_handler(SIGINT, lambda: None)

if __name__ == '__main__':
 asyncio.run(main())
```

<ol>
<li>
از آنجایی که ()asyncio.run کنترل راه‌اندازی حلقه‌ی رویداد را به دست می‌گیرد، اولین فرصت ما برای تغییر رفتار کنترل‌کننده سیگنال در تابع ()main خواهد بود. 
</li>
<li>
درون کنترل‌کننده سیگنال، نمی‌توانیم مانند مثال‌های قبلی حلقه را متوقف کنیم، زیرا هشدارهایی درباره نحوه توقف حلقه پیش از کامل شدن تسکی که برای ()main ساخته شده بود خواهیم گرفت. به جای این کار، می‌توانیم لغو task را در اینجا آغاز کنیم، که در نهایت موجب خروج تسک ()main خواهد شد؛ زمانی که این اتفاق بیفتد،‌ کنترل پاکسازی درون ()asyncio.run مسئولیت را بر عهده خواهد گرفت. 
</li>
</ol>

### صبر کردن برای اجراکننده در حین خاموشی

بخش ["شروع سریع"](#quickstart) در صفحه 22 اجراکننده‌ی پایه را با مثال 3-3 معرفی کرد، که من نیز به این مسئله اشاره کردم که فراخوانی مسدودکننده‌ی ()time.sleep از فراخوانی ()asyncio.run کوتاه‌تر است. این مسئله برای ما خوب است زیرا بدان معناست که task مربوط به اجراکننده زودتر از تابع ()main که coroutine است کامل می‌شود، و در نتیجه برنامه به درستی خاموش می‌شود. 

این بخش بررسی می‌کند که در حین خاموشی و در زمانی که تمام شدن jobهای اجراکننده بیش‌تر از instanceهای Task به طول می‌انجامد چه اتفاقی می‌افتد. جواب کوتاه این است که بدون مداخله، خطاهایی مانند مثال 36-3 خواهید گرفت. 

مثال 36-3. اتمام کار اجراکننده بیش از اندازه طول می‌کشد

``` python
# quickstart.py
import time
import asyncio

async def main():
    loop = asyncio.get_running_loop()
    loop.run_in_executor(None, blocking)
    print(f'{time.ctime()} Hello!')
    await asyncio.sleep(1.0)
    print(f'{time.ctime()} Goodbye!')

def blocking():
    time.sleep(1.5) #1
    print(f"{time.ctime()} Hello from a thread!")
 
asyncio.run(main())
```

<ol>
<li>
این مثال دقیقا مانند مثال 3-3 است، با این تفاوت که زمان خوابیدن در تابع مسدودکننده طولانی‌تر از نمونه‌ی async است.
اجرای این برنامه خروجی زیر را تولید می‌کند.
</li>
</ol>

``` shell
$ python quickstart.py
Fri Jan 24 16:25:08 2020 Hello!
Fri Jan 24 16:25:09 2020 Goodbye!
exception calling callback for <Future at [...snip...]>
Traceback (most recent call last):

<big nasty traceback>

RuntimeError: Event loop is closed
Fri Jan 24 16:25:09 2020 Hello from a thread!
```

اتفاقی که در اینجا می‌افتد این است که در پشت صحنه، تابع ()run_in_executer یک نمونه از Task نمی‌سازد: بلکه یک Future بازمی‌گرداند. این بدان معناست که این خروجی در مجموعه‌ی taskهای فعال که درون ()asyncio.run لغو می‌شوند قرار نمی‌گیرد، و بدین ترتیب ()run_until_complete (که درون ()asyncio.run فراخوانی می‌شود) برای اتمام کار اجراکننده صبر نمی‌کند. خطای RuntimeError از درون فراخوانی ()loop.close که درون ()asyncio.run اجرا می‌شود رخ می‌دهد. 

در زمانی که این مطالب را می‌نویسم، ()loop.close در Python 3.8 برای اتمام تمام jobهای اجرا کننده صبر نمی‌کند، و به همین دلیل است که Future از ()run_in_executer بازگردانده شده شکایت می‌کند: تا زمانی که این مسئله حل شود، حلقه قبلا بسته شده است. بحث‌هایی برای بهبود این مورد در تیم توسعه‌دهنده‌ی اصلی پایتون در جریان است. اما تا زمانی که راه حلی برای این مورد پیدا شود، به یک استراتژی برای کنترل کردن این خطاها نیاز خواهیم داشت. 

<img style="float: left;width:120px;height:120px" src="./images/2.png">

در پایتون 3.9، تابع ()asyncio.run [بهبود یافته است](https://bugs.python.org/issue34037) تا به درستی برای خاموشیِ اجراکننده صبر کند، اما در زمان نوشتن این مطلب، این مسئله هنوز در پایتون 3.8 گزارش نشده است. 

چندین ایده برای درست کردن این مسئله به ذهن می‌رسد، هر یک با مزایا و معایب مختلف، و ما می‌خواهیم به برخی از آن‌ها نگاهی بیندازیم. هدف واقعی من از این تمرین این است که به شما کمک کنم با در نظر گرفتن مدیریت حیات تمام coroutineها، threadها، , و فرایندهای فرعی که ممکن است باهم در برنامه کار کنند، درباره چرخه‌ی حیات حلقه رویداد از جنبه‌های مختلفی فکر کنید.

اولین ایده-و البته آسان‌ترین ایده برای پیاده سازی که در مثال 37-3 نشان داده شده است-این است که همیشه یک تسک اجراکننده را از درون یک await، coroutine کنیم. 

مثال 37-3. گزینه اول: فراخوانی اجراکننده را درون یک coroutine قرار دهید. 

``` python
# quickstart.py
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor as Executor

async def main():
    loop = asyncio.get_running_loop()
    future = loop.run_in_executor(None, blocking) #1
    try:
        print(f'{time.ctime()} Hello!')
        await asyncio.sleep(1.0)
        print(f'{time.ctime()} Goodbye!')
    finally:
        await future #2

def blocking():
    time.sleep(2.0)
    print(f"{time.ctime()} Hello from a thread!")

try:
    asyncio.run(main())
except KeyboardInterrupt:
    print('Bye!')
```

<ol>
<li>
هدف این ایده رفع این مشکل است که ()run_in_executer تنها یک instance از Future و نه یک instance از task بازمی گرداند. ما نمی‌توانیم job را در ()all_tasksبه دست آوریم (که در ()asyncio.run مورد استفاده قرار می‌گیرد)، اما می‌توانیم از await بر روی Future استفاده کنیم. اولین بخش از نقشه این است یک future در تابع ()mainبسازیم. 
</li>
<li>
می‌توانیم از ساختار try/finally استفاده کنیم تا مطمئن شویم که برای اتمام future پیش از بازگشت از تابع ()main صبر می‌کنیم. 
</li>
</ol>

کد کار می‌کند، اما محدودیت زیادی بر مدیریت حیات تابع اجراکننده اعمال می‌کند: این بدان معناست که باید از یک try/finally درون هر محدوده‌ای که یک job اجراکننده ساخته می‌شود استفاده کنیم. ترجیح می‌دهیم jobهای اجراکننده را به همان شیوه‌ای که async taskها را می‌سازیم ایجاد کنیم، و همچنان کنترل خاموش شدن در ()asyncio.run به درستی انجام می‌شود. 

ایده بعدی که در مثال 38-3 نشان داده شده است کمی فریب‌دهنده است. از آنجایی که مشکل ما این است که اجراکننده به جای ساخت task، یک future می‌سازد، و روند خاموشی در ()asyncio.run با taskها کار می کند، نقشه بعدی ما این است که future ساخته شده توسط اجراکننده را درون یک شئ task قرار دهیم. 

مثال 38-3. گزینه دوم: future اجراکننده را به taskهای جمع‌آوری شده اضافه کنید. 

``` python
# quickstart.py
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor as Executor

async def make_coro(future): #2
    try:
        return await future
    except asyncio.CancelledError:
        return await future
async def main():
    loop = asyncio.get_running_loop()
    future = loop.run_in_executor(None, blocking)
    asyncio.create_task(make_coro(future)) #1
    print(f'{time.ctime()} Hello!')
    await asyncio.sleep(1.0)
    print(f'{time.ctime()} Goodbye!')
    
def blocking():
    time.sleep(2.0)
    print(f"{time.ctime()} Hello from a thread!")

try:
    asyncio.run(main())
except KeyboardInterrupt:
    print('Bye!')
```

<ol>
<li>
ما future بازگردانده شده از فراخوانی ()run_in_executer را به تابع کاربردی جدید، ()make_coro، پاس می‌دهیم. نکته مهم در اینجا این است که ما از ()create_task استفاده می‌کنیم، که بدان معناست که این task در لیست ()all_tasks درون کنترل‌کننده‌ی فرایند خاموشی در ()asyncio.run ظاهر می‌شود، و در فرایند خاموشی دستور لغو دریافت خواهد کرد. 
</li>
<li>
 تابع کاربردی ()make_coro به سادگی برای اتمام future صبر می‌کند، اما بسیار مهم است که این تابع به صبر کردن برای future حتی در در کنترل‌کننده‌ی خطا برای CancelledError نیز ادامه می‌دهد.  
</li>
</ol>

این راه حل در زمان خاموشی بهتر عمل می‌کند. من شما را تشویق می‌کنم که این مثال را اجرا کرده و بلافاصله پس از چاپ پیام "!Hello" کلید Ctrl-C را فشار دهید. این روند خاموشی همچنان برای خروج ()make_coro صبر می‌کند، که بدان معناست که همچنان برای خروج job اجراکننده نیز صبر می‌کند. با این وجود، این کد بسیار خام است، زیرا باید تمام نمونه‌های Future که از اجراکننده ایجاد می‌شوند را درون فراخوانی ()make_coro قرار دهیم. 

اگر مایلیم از راحتی تابع ()asyncio.run صرف نظر کنیم (تا زمانی که پایتون 3.9 در دسترس قرار گیرد)، می‌توانیم با استفاده از کنترل‌کننده‌ی حلقه سفارشی‌شده بهتر عمل کنیم، که در مثال 39-3 نشان داده شده است. 

مثال 39-3. گزینه سوم: درست مانند کمپ کردن، حلقه و اجراکننده‌ی خود را بیاورید. 


``` python
# quickstart.py
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor as Executor

async def main():
    print(f'{time.ctime()} Hello!')
    await asyncio.sleep(1.0)
    print(f'{time.ctime()} Goodbye!')
    loop.stop()

def blocking():
    time.sleep(2.0)
    print(f"{time.ctime()} Hello from a thread!")

loop = asyncio.get_event_loop()
executor = Executor() #1
loop.set_default_executor(executor) #2
loop.create_task(main())
future = loop.run_in_executor(None, blocking) #3

try:
    loop.run_forever()
except KeyboardInterrupt:
    print('Cancelled')

tasks = asyncio.all_tasks(loop=loop)
for t in tasks:
    t.cancel()
group = asyncio.gather(*tasks, return_exceptions=True)
loop.run_until_complete(group)
executor.shutdown(wait=True) #4
loop.close()
```

<ol>
<li>
این بار، نمونه اجراکننده‌مان را خودمان می‌سازیم. 
</li>
<li>
باید اجراکننده‌ی سفارشی خود را به عنوان پیش‌فرض برای حلقه قرار دهیم. این بدان معناست که هر جا در برنامه که ()run_in_executer فراخوانی می‌شود، از اجراکننده‌ی سفارشی ما استفاده می‌شود. 
</li>
<li>
مانند قبل، تابع مسدودکننده را اجرا می‌کنیم. 
</li>
<li>
در نهایت، می‌توانیم برای اتمام همه‌ی jobهای اجراکننده پیش از بسته شدن حلقه صبر کنیم. این کار از پیام‌های  “Event loop is closed”  که پیش‌تر دیدیم جلوگیری می‌کند. ما می‌توانیم این کار را انجام دهیم زیرا به شئ اجراکننده دسترسی داریم. اجراکننده پیش‌فرض در API کتابخانه asyncio آشکار نیست، که به همین دلیل هم نمی‌توانیم ()shutdown را برای آن فراخوانی کنیم و مجبور شدیم instance اجراکننده خودمان را ایجاد کنیم. 
</li>
</ol>

در نهایت،‌ ما یک استراتژی با کاربردیِ کلی داریم: شما می‌توانید ()run_in_executer را در همه جا فراخوانی کنید، و برنامه‌تان همچنان به درستی خاموش خواهد شد، حتی اگر jobهای اجراکننده همچنان پس از اتمام taskهای async  در حال اجرا باشند. 

به شدت شما را تشویق می کنم که با مثال‌‌های نشان داده شده کار کنید و استراتژی‌های متفاوت برای ساخت taskها و jobهای اجراکننده و تغییر آن‌ها برای خاموشی‌ِ صحیح را امتحان کنید. انتظار دارم یکی از نسخه‌های آینده‌ی پایتون اجازه دهد که تابع ()asyncio.run به صورت داخلی برای پایان jobهای اجراکننده صبر کند، اما همچنان امیدوارم مباحث این بخش برای توسعه تفکر شما درباره خاموشی صحیح مفید باشد. 


[^1]: البته زمانی که در دسترس قرار گیرند! در زمانی که این مطالب را می‌نویسم،‌ تنها مراجع در دسترس برای asyncio مشخصات API در داکیومنت رسمی پایتون و مجموعه‌ای از پست‌های وبلاگ است، که چندین مورد از آن‌ها در این کتاب لینک شده‌اند.

<p dir='rtl'>
[^2]: API کتابخانه asyncio به شما اجازه می‌دهد با استفاده از چندین نمونه از حلقه‌ها و threadها کارهای جالبی انجام دهید، اما این کتاب مکان مناسبی برای بیان این مطالب نیست. 99٪ از مواقع همانطور که در اینجا نشان داده شده است به استفاده از تنها یک thread اصلی در برنامه خود نیاز خواهید داشت. 
</p>

[^3]: استفاده از نام پارامتر `coro` یک قرارداد رایج در داکیومنت API است که به یک coroutine اشاره دارد؛ در واقع همان چیزی که از فراخوانی یک تابع async def و نه خود تابع بازمی‌گردد.

[^4]: متاسفانه، اولین پارامتر ()run_in_executer یک instance از Executer برای استفاده است،‌ و برای آنکه بتوانید از پیش فرض این پارامتر استفاده کنید باید None را به تابع پاس دهید. هر زمان که از این استفاده می‌کنم، احساس می‌کنم که پارامتر "executer" خواستار آن است که یک kwarg با مقدار پیش‌ فرض None باشد. 

[^5]: علاوه بر این، این همان شیوه‌ای است که باقی کتابخانه‌های متن باز مانند Twisted و Torando در گذشته از async پشتیبانی می‌کردند. 

[^6]: همچنین یک coroutine قدیمی مبتنی بر generator که یک تابع مولد با دکوراتور types.coroutine@ که از کلیدواژه‌ی yield به صورت داخلی برای تعلیق استفاده می‌کند نیز قابل قبول است. ما در این کتاب به طور کامل از coroutineهای قدیمی صرف نظر می‌کنیم. آن‌ها را از ذهن خود پاک کنید. 

[^7]: داکیومنت در این قسمت متناقض است: امضا به عنوان (future)AbstractEventLoop.run_until_com plete داده شده است، اما در واقع باید (coro_or_future) AbstractEventLoop.run_until_complete باشد، زیرا همان قوانین اعمال می شوند. 

[^8]: اضافه کردن پشتیبانی async به فریمورکی که از پیش وجود داشته است بسیار دشوار است، زیرا ممکن است به تغییرات ساختاری بزرگی در کد نیاز باشد. این مسئله در [GitHub issue for requests](https://github.com/psf/requests/issues/2801) مورد بحث قرار گرفته است. 

[^9]: بله، این بسیار آزاردهنده است. هر زمان که از این فراخوانی استفاده می‌کنم، به این فکر می‌کنم که چرا استفاده از executer=None به عنوان یک keyword argument ترجیح داده نشده است. 

[^10]: تابع ()add_signal_handler احتمالا باید ()set_signal_handler نامیده شود، زیرا شما می‌توانید برای هر نوع سیگنال تنها یک کنترل‌کننده داشته باشید؛ فراخوانیِ مجدد ()add_signal_handler برای یک سیگنال یکسان، جایگزین کنترل‌کننده‌ی موجود برای همان سیگنال خواهد شد. 
